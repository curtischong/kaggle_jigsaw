{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "from fastai.train import Learner\n",
    "from fastai.train import DataBunch\n",
    "from fastai.callbacks import *\n",
    "from fastai.basic_data import DatasetType\n",
    "import fastprogress\n",
    "from fastprogress import force_console_behavior\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import random\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_aux_targets):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "    \n",
    "        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        \n",
    "        ###New code\n",
    "        self.linear3 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        \n",
    "        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n",
    "        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x, lengths=None):\n",
    "        h_embedding = self.embedding(x.long())\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        h_lstm1, _ = self.lstm1(h_embedding)\n",
    "        ### Original code, simpler model\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        h_lstm2 = h_lstm1 + h_lstm2\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1)\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_lstm2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "        hidden = F.tanh(self.linear3(hidden))\n",
    "        \n",
    "        ### ORIGINAL CODE\n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        \n",
    "        #result = F.sigmoid(self.linear_out(hidden))\n",
    "        #aux_result = F.sigmoid(self.linear_aux_out(hidden))\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in /home/curtis/miniconda3/lib/python3.7/site-packages (1.0.52)\n",
      "Collecting numpy>=1.15 (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (3.0.3)\n",
      "Requirement already satisfied: Pillow in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (5.1)\n",
      "Requirement already satisfied: bottleneck in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (1.2.1)\n",
      "Requirement already satisfied: requests in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (2.21.0)\n",
      "Requirement already satisfied: pandas in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (0.24.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (1.1.0)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied: typing in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (3.6.6)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (2.1.4)\n",
      "Requirement already satisfied: packaging in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (19.0)\n",
      "Requirement already satisfied: torchvision in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (0.2.2.post3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (4.7.1)\n",
      "Requirement already satisfied: numexpr in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (2.6.9)\n",
      "Requirement already satisfied: fastprogress>=0.1.19 in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (0.1.21)\n",
      "Requirement already satisfied: scipy in /home/curtis/miniconda3/lib/python3.7/site-packages (from fastai) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/curtis/miniconda3/lib/python3.7/site-packages (from matplotlib->fastai) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/curtis/miniconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/curtis/miniconda3/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/curtis/miniconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.8.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/curtis/miniconda3/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/curtis/miniconda3/lib/python3.7/site-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/curtis/miniconda3/lib/python3.7/site-packages (from requests->fastai) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/curtis/miniconda3/lib/python3.7/site-packages (from requests->fastai) (2019.3.9)\n",
      "Requirement already satisfied: pytz>=2011k in /home/curtis/miniconda3/lib/python3.7/site-packages (from pandas->fastai) (2019.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (7.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.2.2)\n",
      "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (3.0.1)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /home/curtis/miniconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.0.5)\n",
      "Requirement already satisfied: six in /home/curtis/miniconda3/lib/python3.7/site-packages (from packaging->fastai) (1.12.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /home/curtis/miniconda3/lib/python3.7/site-packages (from beautifulsoup4->fastai) (1.9.1)\n",
      "Requirement already satisfied: setuptools in /home/curtis/miniconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (41.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.0.18->fastai) (4.32.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from jsonschema<3.1.0,>=2.6.0->spacy>=2.0.18->fastai) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/curtis/miniconda3/lib/python3.7/site-packages (from jsonschema<3.1.0,>=2.6.0->spacy>=2.0.18->fastai) (0.15.2)\n",
      "\u001b[31mERROR: mxnet 1.4.0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bert-embedding 1.0.1 has requirement numpy==1.14.6, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.14.6\n",
      "    Uninstalling numpy-1.14.6:\n",
      "      Successfully uninstalled numpy-1.14.6\n",
      "Successfully installed numpy-1.16.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/__init__.py\", line 167, in <module>\n",
      "    core.getlimits._register_known_types()\n",
      "AttributeError: module 'numpy.core.getlimits' has no attribute '_register_known_types'\n",
      "]\n",
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/lib/__init__.py\", line 32, in <module>\n",
      "    __all__ += type_check.__all__\n",
      "NameError: name 'type_check' is not defined\n",
      "]\n",
      "[autoreload of numpy.core failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/__init__.py\", line 91, in <module>\n",
      "    raise ImportError(msg.format(path))\n",
      "ImportError: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/home/curtis/miniconda3/lib/python3.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.\n",
      "]\n",
      "[autoreload of numpy.core.numerictypes failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/numerictypes.py\", line 111, in <module>\n",
      "    from ._type_aliases import (\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/_type_aliases.py\", line 63, in <module>\n",
      "    _concrete_types = {v.type for k, v in _concrete_typeinfo.items()}\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/_type_aliases.py\", line 63, in <setcomp>\n",
      "    _concrete_types = {v.type for k, v in _concrete_typeinfo.items()}\n",
      "AttributeError: 'tuple' object has no attribute 'type'\n",
      "]\n",
      "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/numeric.py\", line 3098, in <module>\n",
      "    extend_all(umath)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/numeric.py\", line 3085, in extend_all\n",
      "    mall = getattr(module, '__all__')\n",
      "AttributeError: module 'numpy.core.umath' has no attribute '__all__'\n",
      "]\n",
      "[autoreload of numpy.core.records failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/records.py\", line 45, in <module>\n",
      "    from numpy.compat import isfileobj, bytes, long, unicode, os_fspath\n",
      "ImportError: cannot import name 'os_fspath' from 'numpy.compat' (/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/compat/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.core.memmap failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/memmap.py\", line 5, in <module>\n",
      "    from numpy.compat import (\n",
      "ImportError: cannot import name 'os_fspath' from 'numpy.compat' (/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/compat/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.lib.function_base failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\", line 35, in <module>\n",
      "    from numpy.core.multiarray import (\n",
      "ImportError: cannot import name '_monotonicity' from 'numpy.core.multiarray' (/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/multiarray.cpython-37m-x86_64-linux-gnu.so)\n",
      "]\n",
      "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/matrixlib/__init__.py\", line 8, in <module>\n",
      "    __all__ = defmatrix.__all__\n",
      "NameError: name 'defmatrix' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib.mixins failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/lib/mixins.py\", line 63, in <module>\n",
      "    class NDArrayOperatorsMixin(object):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/lib/mixins.py\", line 156, in NDArrayOperatorsMixin\n",
      "    um.matmul, 'matmul')\n",
      "AttributeError: module 'numpy.core.umath' has no attribute 'matmul'\n",
      "]\n",
      "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 25, in <module>\n",
      "    from numpy.compat import (\n",
      "ImportError: cannot import name 'os_fspath' from 'numpy.compat' (/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/compat/__init__.py)\n",
      "]\n",
      "[autoreload of numpy.lib.format failed: Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\", line 164, in <module>\n",
      "    from numpy.compat import (\n",
      "ImportError: cannot import name 'os_fspath' from 'numpy.compat' (/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/compat/__init__.py)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAWL_EMBEDDING_PATH = '../input/crawl-300d-2M.pkl'\n",
    "GLOVE_EMBEDDING_PATH = '../input/glove.840B.300d.pkl'\n",
    "MODEL_LOC = \"Asdasd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 2\n",
    "LSTM_UNITS = 128\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "MAX_LEN = 220\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "\n",
    "def load_embeddings(path):\n",
    "    with open(path,'rb') as f:\n",
    "        emb_arr = pickle.load(f)\n",
    "    return emb_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(word_index, path):\n",
    "    embedding_index = load_embeddings(path)\n",
    "    embedding_matrix = np.zeros((max_features + 1, 300))\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i <= max_features:\n",
    "            try:\n",
    "                embedding_matrix[i] = embedding_index[word]\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    embedding_matrix[i] = embedding_index[word.lower()]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        embedding_matrix[i] = embedding_index[word.title()]\n",
    "                    except KeyError:\n",
    "                        unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "\n",
    "def train_model(learn,test,output_dim,lr=0.001,\n",
    "                batch_size=512, n_epochs=5,\n",
    "                enable_checkpoint_ensemble=True):\n",
    "    \n",
    "    all_test_preds = []\n",
    "    checkpoint_weights = [1,2,4,8,6]\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    n = len(learn.data.train_dl)\n",
    "    phases = [(TrainingPhase(n).schedule_hp('lr', lr * (0.6**(i)))) for i in range(n_epochs)]\n",
    "    sched = GeneralScheduler(learn, phases)\n",
    "    learn.callbacks.append(sched)\n",
    "    for epoch in range(n_epochs):\n",
    "        learn.fit(1)\n",
    "        test_preds = np.zeros((len(test), output_dim))    \n",
    "        for i, x_batch in enumerate(test_loader):\n",
    "            X = x_batch[0].cuda()\n",
    "            ### Regression Predictions\n",
    "            #y_pred = sigmoid(learn.model(X).detach().cpu().numpy())\n",
    "            y_pred = learn.model(X).detach().cpu().numpy()\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred\n",
    "\n",
    "        all_test_preds.append(test_preds)\n",
    "\n",
    "\n",
    "    if enable_checkpoint_ensemble:\n",
    "        test_preds = np.average(all_test_preds, weights=checkpoint_weights, axis=0)    \n",
    "    else:\n",
    "        test_preds = all_test_preds[-1]\n",
    "        \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_hdf('../input/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_isolate = '.,?!-;*\"…:—()%#$&_/@＼・ω+=”“[]^–>\\\\°<~•≠™ˈʊɒ∞§{}·τα❤☺ɡ|¢→̶`❥━┣┫┗Ｏ►★©―ɪ✔®\\x96\\x92●£♥➤´¹☕≈÷♡◐║▬′ɔː€۩۞†μ✒➥═☆ˌ◄½ʻπδηλσερνʃ✬ＳＵＰＥＲＩＴ☻±♍µº¾✓◾؟．⬅℅»Вав❣⋅¿¬♫ＣＭβ█▓▒░⇒⭐›¡₂₃❧▰▔◞▀▂▃▄▅▆▇↙γ̄″☹➡«φ⅓„✋：¥̲̅́∙‛◇✏▷❓❗¶˚˙）сиʿ✨。ɑ\\x80◕！％¯−ﬂﬁ₁²ʌ¼⁴⁄₄⌠♭✘╪▶☭✭♪☔☠♂☃☎✈✌✰❆☙○‣⚓年∎ℒ▪▙☏⅛ｃａｓǀ℮¸ｗ‚∼‖ℳ❄←☼⋆ʒ⊂、⅔¨͡๏⚾⚽Φ×θ￦？（℃⏩☮⚠月✊❌⭕▸■⇌☐☑⚡☄ǫ╭∩╮，例＞ʕɐ̣Δ₀✞┈╱╲▏▕┃╰▊▋╯┳┊≥☒↑☝ɹ✅☛♩☞ＡＪＢ◔◡↓♀⬆̱ℏ\\x91⠀ˤ╚↺⇤∏✾◦♬³の｜／∵∴√Ω¤☜▲↳▫‿⬇✧ｏｖｍ－２０８＇‰≤∕ˆ⚜☁'\n",
    "symbols_to_delete = '\\n🍕\\r🐵😑\\xa0\\ue014\\t\\uf818\\uf04a\\xad😢🐶️\\uf0e0😜😎👊\\u200b\\u200e😁عدويهصقأناخلىبمغر😍💖💵Е👎😀😂\\u202a\\u202c🔥😄🏻💥ᴍʏʀᴇɴᴅᴏᴀᴋʜᴜʟᴛᴄᴘʙғᴊᴡɢ😋👏שלוםבי😱‼\\x81エンジ故障\\u2009🚌ᴵ͞🌟😊😳😧🙀😐😕\\u200f👍😮😃😘אעכח💩💯⛽🚄🏼ஜ😖ᴠ🚲‐😟😈💪🙏🎯🌹😇💔😡\\x7f👌ἐὶήιὲκἀίῃἴξ🙄Ｈ😠\\ufeff\\u2028😉😤⛺🙂\\u3000تحكسة👮💙فزط😏🍾🎉😞\\u2008🏾😅😭👻😥😔😓🏽🎆🍻🍽🎶🌺🤔😪\\x08‑🐰🐇🐱🙆😨🙃💕𝘊𝘦𝘳𝘢𝘵𝘰𝘤𝘺𝘴𝘪𝘧𝘮𝘣💗💚地獄谷улкнПоАН🐾🐕😆ה🔗🚽歌舞伎🙈😴🏿🤗🇺🇸мυтѕ⤵🏆🎃😩\\u200a🌠🐟💫💰💎эпрд\\x95🖐🙅⛲🍰🤐👆🙌\\u2002💛🙁👀🙊🙉\\u2004ˢᵒʳʸᴼᴷᴺʷᵗʰᵉᵘ\\x13🚬🤓\\ue602😵άοόςέὸתמדףנרךצט😒͝🆕👅👥👄🔄🔤👉👤👶👲🔛🎓\\uf0b7\\uf04c\\x9f\\x10成都😣⏺😌🤑🌏😯ех😲Ἰᾶὁ💞🚓🔔📚🏀👐\\u202d💤🍇\\ue613小土豆🏡❔⁉\\u202f👠》कर्मा🇹🇼🌸蔡英文🌞🎲レクサス😛外国人关系Сб💋💀🎄💜🤢َِьыгя不是\\x9c\\x9d🗑\\u2005💃📣👿༼つ༽😰ḷЗз▱ц￼🤣卖温哥华议会下降你失去所有的钱加拿大坏税骗子🐝ツ🎅\\x85🍺آإشء🎵🌎͟ἔ油别克🤡🤥😬🤧й\\u2003🚀🤴ʲшчИОРФДЯМюж😝🖑ὐύύ特殊作戦群щ💨圆明园קℐ🏈😺🌍⏏ệ🍔🐮🍁🍆🍑🌮🌯🤦\\u200d𝓒𝓲𝓿𝓵안영하세요ЖљКћ🍀😫🤤ῦ我出生在了可以说普通话汉语好极🎼🕺🍸🥂🗽🎇🎊🆘🤠👩🖒🚪天一家⚲\\u2006⚭⚆⬭⬯⏖新✀╌🇫🇷🇩🇪🇮🇬🇧😷🇨🇦ХШ🌐\\x1f杀鸡给猴看ʁ𝗪𝗵𝗲𝗻𝘆𝗼𝘂𝗿𝗮𝗹𝗶𝘇𝗯𝘁𝗰𝘀𝘅𝗽𝘄𝗱📺ϖ\\u2000үսᴦᎥһͺ\\u2007հ\\u2001ɩｙｅ൦ｌƽｈ𝐓𝐡𝐞𝐫𝐮𝐝𝐚𝐃𝐜𝐩𝐭𝐢𝐨𝐧Ƅᴨןᑯ໐ΤᏧ௦Іᴑ܁𝐬𝐰𝐲𝐛𝐦𝐯𝐑𝐙𝐣𝐇𝐂𝐘𝟎ԜТᗞ౦〔Ꭻ𝐳𝐔𝐱𝟔𝟓𝐅🐋ﬃ💘💓ё𝘥𝘯𝘶💐🌋🌄🌅𝙬𝙖𝙨𝙤𝙣𝙡𝙮𝙘𝙠𝙚𝙙𝙜𝙧𝙥𝙩𝙪𝙗𝙞𝙝𝙛👺🐷ℋ𝐀𝐥𝐪🚶𝙢Ἱ🤘ͦ💸ج패티Ｗ𝙇ᵻ👂👃ɜ🎫\\uf0a7БУі🚢🚂ગુજરાતીῆ🏃𝓬𝓻𝓴𝓮𝓽𝓼☘﴾̯﴿₽\\ue807𝑻𝒆𝒍𝒕𝒉𝒓𝒖𝒂𝒏𝒅𝒔𝒎𝒗𝒊👽😙\\u200cЛ‒🎾👹⎌🏒⛸公寓养宠物吗🏄🐀🚑🤷操美𝒑𝒚𝒐𝑴🤙🐒欢迎来到阿拉斯ספ𝙫🐈𝒌𝙊𝙭𝙆𝙋𝙍𝘼𝙅ﷻ🦄巨收赢得白鬼愤怒要买额ẽ🚗🐳𝟏𝐟𝟖𝟑𝟕𝒄𝟗𝐠𝙄𝙃👇锟斤拷𝗢𝟳𝟱𝟬⦁マルハニチロ株式社⛷한국어ㄸㅓ니͜ʖ𝘿𝙔₵𝒩ℯ𝒾𝓁𝒶𝓉𝓇𝓊𝓃𝓈𝓅ℴ𝒻𝒽𝓀𝓌𝒸𝓎𝙏ζ𝙟𝘃𝗺𝟮𝟭𝟯𝟲👋🦊多伦🐽🎻🎹⛓🏹🍷🦆为和中友谊祝贺与其想象对法如直接问用自己猜本传教士没积唯认识基督徒曾经让相信耶稣复活死怪他但当们聊些政治题时候战胜因圣把全堂结婚孩恐惧且栗谓这样还♾🎸🤕🤒⛑🎁批判检讨🏝🦁🙋😶쥐스탱트뤼도석유가격인상이경제황을렵게만들지않록잘관리해야합다캐나에서대마초와화약금의품런성분갈때는반드시허된사용🔫👁凸ὰ💲🗯𝙈Ἄ𝒇𝒈𝒘𝒃𝑬𝑶𝕾𝖙𝖗𝖆𝖎𝖌𝖍𝖕𝖊𝖔𝖑𝖉𝖓𝖐𝖜𝖞𝖚𝖇𝕿𝖘𝖄𝖛𝖒𝖋𝖂𝕴𝖟𝖈𝕸👑🚿💡知彼百\\uf005𝙀𝒛𝑲𝑳𝑾𝒋𝟒😦𝙒𝘾𝘽🏐𝘩𝘨ὼṑ𝑱𝑹𝑫𝑵𝑪🇰🇵👾ᓇᒧᔭᐃᐧᐦᑳᐨᓃᓂᑲᐸᑭᑎᓀᐣ🐄🎈🔨🐎🤞🐸💟🎰🌝🛳点击查版🍭𝑥𝑦𝑧ＮＧ👣\\uf020っ🏉ф💭🎥Ξ🐴👨🤳🦍\\x0b🍩𝑯𝒒😗𝟐🏂👳🍗🕉🐲چی𝑮𝗕𝗴🍒ꜥⲣⲏ🐑⏰鉄リ事件ї💊「」\\uf203\\uf09a\\uf222\\ue608\\uf202\\uf099\\uf469\\ue607\\uf410\\ue600燻製シ虚偽屁理屈Г𝑩𝑰𝒀𝑺🌤𝗳𝗜𝗙𝗦𝗧🍊ὺἈἡχῖΛ⤏🇳𝒙ψՁմեռայինրւդձ冬至ὀ𝒁🔹🤚🍎𝑷🐂💅𝘬𝘱𝘸𝘷𝘐𝘭𝘓𝘖𝘹𝘲𝘫کΒώ💢ΜΟΝΑΕ🇱♲𝝈↴💒⊘Ȼ🚴🖕🖤🥘📍👈➕🚫🎨🌑🐻𝐎𝐍𝐊𝑭🤖🎎😼🕷ｇｒｎｔｉｄｕｆｂｋ𝟰🇴🇭🇻🇲𝗞𝗭𝗘𝗤👼📉🍟🍦🌈🔭《🐊🐍\\uf10aლڡ🐦\\U0001f92f\\U0001f92a🐡💳ἱ🙇𝗸𝗟𝗠𝗷🥜さようなら🔼'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "small_caps_mapping = { \n",
    "\"ᴀ\": \"a\", \"ʙ\": \"b\", \"ᴄ\": \"c\", \"ᴅ\": \"d\", \"ᴇ\": \"e\", \"ғ\": \"f\", \"ɢ\": \"g\", \"ʜ\": \"h\", \"ɪ\": \"i\", \n",
    "\"ᴊ\": \"j\", \"ᴋ\": \"k\", \"ʟ\": \"l\", \"ᴍ\": \"m\", \"ɴ\": \"n\", \"ᴏ\": \"o\", \"ᴘ\": \"p\", \"ǫ\": \"q\", \"ʀ\": \"r\", \n",
    "\"s\": \"s\", \"ᴛ\": \"t\", \"ᴜ\": \"u\", \"ᴠ\": \"v\", \"ᴡ\": \"w\", \"x\": \"x\", \"ʏ\": \"y\", \"ᴢ\": \"z\"}\n",
    "contraction_mapping = {\n",
    "\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "\"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "\"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \n",
    "\"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \n",
    "\"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \n",
    "\"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \n",
    "\"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \n",
    "\"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n",
    "\"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "\"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\":\"this is\",\"that'd\": \"that would\", \n",
    "\"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \n",
    "\"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \n",
    "\"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \n",
    "\"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \n",
    "\"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "\"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "\"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "\"trump's\": \"trump is\", \"obama's\": \"obama is\", \"canada's\": \"canada is\", \"today's\": \"today is\"}\n",
    "specail_signs = { \"…\": \"...\", \"₂\": \"2\"}\n",
    "specials = [\"’\", \"‘\", \"´\", \"`\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curtis/miniconda3/lib/python3.7/site-packages/numpy/core/getlimits.py:400: UserWarning: Signature b'\\x9a\\x99\\x99\\x99\\x99\\x99\\xb9\\xbf' for <class 'numpy.float64'> does not match any known type: falling back to type probe function\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "\n",
    "isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\n",
    "remove_dict = {ord(c):f'' for c in symbols_to_delete}\n",
    "\n",
    "\n",
    "def handle_punctuation(x):\n",
    "    x = x.translate(remove_dict)\n",
    "    x = x.translate(isolate_dict)\n",
    "    return x\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = tokenizer.tokenize(x)\n",
    "    return x\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def preprocess(x):\n",
    "    x = handle_punctuation(x)\n",
    "    x = handle_contractions(x)\n",
    "    x = fix_quote(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18eb857bcc7346feaf19c6eb2ad0fde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=97320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test = test['comment_text'].progress_apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 410047\n",
    "maxlen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n unknown words (crawl):  14305\n",
      "n unknown words (glove):  14601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer(num_words = max_features, filters='',lower=False)\n",
    "tokenizer.fit_on_texts(list(x_test))\n",
    "\n",
    "crawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n",
    "print('n unknown words (crawl): ', len(unknown_words_crawl))\n",
    "\n",
    "glove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n",
    "print('n unknown words (glove): ', len(unknown_words_glove))\n",
    "\n",
    "max_features = max_features or len(tokenizer.word_index) + 1\n",
    "max_features\n",
    "\n",
    "embedding_matrix = np.concatenate([crawl_matrix, glove_matrix], axis=-1)\n",
    "embedding_matrix.shape\n",
    "\n",
    "del crawl_matrix\n",
    "del glove_matrix\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([97320, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lengths = torch.from_numpy(np.array([len(x) for x in x_test]))\n",
    "\n",
    "x_test_padded = torch.from_numpy(sequence.pad_sequences(x_test, maxlen=maxlen))\n",
    "x_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:56] posix_memalign(&data, gAlignment, nbytes) == 0. 12 vs 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-10fb08744f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1cc9b01c625c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mh_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mh_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m         return F.embedding(\n\u001b[1;32m    116\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:56] posix_memalign(&data, gAlignment, nbytes) == 0. 12 vs 0\n"
     ]
    }
   ],
   "source": [
    "# honestly the embedding matrix here is filler to get the declaration to work\n",
    "model = NeuralNet(embedding_matrix, num_aux_targets=6)\n",
    "\n",
    "all_preds = []\n",
    "for model_num in range(NUM_MODELS):\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        cur_model = \"lstm\" + str(epoch) + \"_\" + str(model_num) + \"ensemble_tune\"\n",
    "        temp_dict = torch.load(cur_model)\n",
    "        temp_dict['embedding.weight'] = torch.tensor(embedding_matrix)\n",
    "\n",
    "        model.load_state_dict(temp_dict)\n",
    "\n",
    "        model.eval()\n",
    "        all_preds.append(sigmoid(model(x_test_padded).data.numpy()[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test['id'],\n",
    "    'prediction': np.mean(all_preds, axis=0)[:, 0]\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
