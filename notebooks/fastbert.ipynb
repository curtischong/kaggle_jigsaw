{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/huggingface/introducing-fastbert-a-simple-deep-learning-library-for-bert-models-89ff763ad384\n",
    "import torch\n",
    "import apex\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "from fast_bert.data import BertDataBunch\n",
    "from fast_bert.learner import BertLearner\n",
    "from fast_bert.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train, val, and labels files\n",
    "train = pd.read_hdf('../input/train.h5')\n",
    "test = pd.read_hdf('../input/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/'     # path for data files (train and val)\n",
    "LABEL_PATH = '../labels/'  # path for labels file\n",
    "MODEL_PATH='../models/'    # path for model artifacts to be stored\n",
    "LOG_PATH='../logs/'       # path for log files to be stored\n",
    "\n",
    "# location for the pretrained BERT models\n",
    "BERT_PRETRAINED_PATH = '../input/bert-pretrained-models/uncased_L-12_H-768_A-12/'\n",
    "\n",
    "args = {\n",
    "    \"max_seq_length\": 512,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"learning_rate\": 6e-5,\n",
    "    \"num_train_epochs\": 12.0,\n",
    "    \"warmup_proportion\": 0.002,\n",
    "    \"local_rank\": -1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"fp16\": True,\n",
    "    \"loss_scale\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_PRETRAINED_PATH, \n",
    "                                          do_lower_case=args['do_lower_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# check if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    multi_gpu = True\n",
    "else:\n",
    "    multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = BertDataBunch(DATA_PATH, LABEL_PATH, tokenizer, \n",
    "                          train_file='train.csv', val_file='val.csv', label_file='labels.csv',\n",
    "                          bs=args['train_batch_size'], maxlen=args['max_seq_length'], \n",
    "                          multi_gpu=multi_gpu, multi_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
