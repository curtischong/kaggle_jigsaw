{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, gc, pickle, random\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from bert_embedding import BertEmbedding\n",
    "import apex # used for 16 bit\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mxnet as mx # used for GPU\n",
    "#for getting num good and bad words\n",
    "from wordcloud import STOPWORDS\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import swifter # speed up feature gen - multiple cores\n",
    "\n",
    "# Logging for BERT\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "string.printable\n",
    "ascii_chars = string.printable\n",
    "ascii_chars += \" áéíóúàèìòùâêîôûäëïöüñõç\"\n",
    "\n",
    "#checks if a string of text contains any nonenglish characters (excluding punctuations, spanish, and french characters)\n",
    "def contains_non_english(text):\n",
    "    if all(char in ascii_chars for char in text):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#clean non english characters from string of text\n",
    "def remove_non_english(text):\n",
    "    return ''.join(filter(lambda x: x in ascii_chars, text))\n",
    "\n",
    "\n",
    "def get_first_word(word):\n",
    "    if(type(word) != \"float\"):\n",
    "        return word.split(\" \")[0]\n",
    "    return \"-1\"\n",
    "\n",
    "def get_cap_vs_length(df):\n",
    "    df['caps_vs_length'] = df['num_caps'].divide(df['num_chars'])\n",
    "    df.loc[~np.isfinite(df['caps_vs_length']), 'caps_vs_length'] = 0\n",
    "    \n",
    "\"\"\"    mask = (df['num_chars'] != 0)\n",
    "    df_valid = df[mask]\n",
    "    \n",
    "    df.loc[mask, 'caps_vs_length'] = df_valid['num_caps'] / df_valid['num_chars']\"\"\"\n",
    "\n",
    "def get_unique_word_over_num_words(df):\n",
    "    df['unique_word_over_num_words'] = df['num_unique_words'].divide(df['num_words'])\n",
    "    df.loc[~np.isfinite(df['unique_word_over_num_words']), 'unique_word_over_num_words'] = 0\n",
    "    \n",
    "def get_avg_word_len(df):\n",
    "    df['avg_word_len'] = df['total_word_length'].divide(df['num_words'])\n",
    "    df.loc[~np.isfinite(df['avg_word_len']), 'avg_word_len'] = 0\n",
    "\n",
    "def get_avg_unique_word_len(df):\n",
    "    df['avg_unique_word_len'] = df['total_unique_word_length'].divide(df['num_unique_words'])\n",
    "    df.loc[~np.isfinite(df['avg_unique_word_len']), 'avg_unique_word_len'] = 0\n",
    "    \n",
    "def calc_max_word_len(sentence):\n",
    "    maxLen = 0\n",
    "    for word in sentence:\n",
    "        maxLen = max(maxLen, len(word))\n",
    "    return maxLen\n",
    "\n",
    "def calc_min_word_len(sentence):\n",
    "    minLen = 999999\n",
    "    for word in sentence:\n",
    "        minLen = min(minLen, len(word))\n",
    "    return minLen\n",
    "\n",
    "def calc_total_word_len(sentence):\n",
    "    cnt = 0\n",
    "    for x in sentence:\n",
    "        cnt+=len(x)\n",
    "    return cnt\n",
    "\n",
    "def calc_total_unique_word_len(sentence):\n",
    "    words = set(sentence)\n",
    "    return calc_total_word_len(words)\n",
    "\n",
    "#removes all single characters except for \"I\" and \"a\"\n",
    "def remove_singles(text):\n",
    "    return ' '.join( [w for w in text.split() if ((len(w)>1) or (w.lower() == \"i\") or (w.lower() == \"a\"))] )\n",
    "    \n",
    "#combines multiple whitespaces into single\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"&/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&':\n",
    "        x = x.replace(punct, '')\n",
    "    x = re.sub( '\\s+', ' ', x).strip()\n",
    "    \n",
    "    \n",
    "# Text cleaning\n",
    "# TODO: speed up this func\n",
    "def pad_chars(text,punct):\n",
    "    for p in punct:\n",
    "        text = re.sub('(?<=\\w)([!?,])', r' \\1', text)\n",
    "    return text\n",
    "    \n",
    "symbols_iv = \"\"\"?,./-()\"$=…*&+′[ɾ̃]%:^\\xa0\\\\{}–“”;!<`®ạ°#²|~√_α→>—£，。´×@π÷？ʿ€の↑∞ʻ℅в•−а年！∈∩⊆§℃θ±≤͡⁴™си≠∂³ி½△¿¼∆≥⇒¬∨∫▾Ω＾γµº♭ー̂ɔ∑εντσ日Γ∪φβ¹∘¨″⅓ɑː✅✓（）∠«»்ுλ∧∀،＝ɨʋδɒ¸☹μΔʃɸηΣ₅₆◦·ВΦ☺❤♨✌≡ʌʊா≈⁰‛：ﬁ„¾ρ⟨⟩˂⅔≅－＞¢⁸ʒは⬇♀؟¡⋅ɪ₁₂ɤ◌ʱ、▒ْ；☉＄∴✏ωɹ̅।ـ☝♏̉̄♡₄∼́̀⁶⁵¦¶ƒˆ‰©¥∅・ﾟ⊥ª†ℕ│ɡ∝♣／☁✔❓∗➡ℝ位⎛⎝¯⎞⎠↓ɐ∇⋯˚⁻ˈ₃⊂˜̸̵̶̷̴̡̲̳̱̪̗̣̖̎̿͂̓̑̐̌̾̊̕\\x92\"\"\"        \n",
    "\n",
    "def split_off_symbols_iv(x):\n",
    "    for punct in symbols_iv:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "    \n",
    "def neutrailize_bad_words(train,test):\n",
    "    train1_df = train[train[\"target\"]==1]\n",
    "    train0_df = train[train[\"target\"]==0]\n",
    "\n",
    "    ## custom function for ngram generation ##\n",
    "    def generate_ngrams(text, n_gram=1):\n",
    "        token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n",
    "        ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    freq_dict_bad = defaultdict(int)\n",
    "    for sent in train1_df[\"comment_text\"]:\n",
    "        for word in generate_ngrams(sent):\n",
    "            freq_dict_bad[word] += 1\n",
    "    freq_dict_bad = dict(freq_dict_bad)\n",
    "\n",
    "    freq_dict_good = defaultdict(int)\n",
    "    for sent in train0_df[\"comment_text\"]:\n",
    "        for word in generate_ngrams(sent):\n",
    "            freq_dict_good[word] += 1\n",
    "    freq_dict_good = dict(freq_dict_good)\n",
    "\n",
    "    bad_words = sorted(freq_dict_bad, key=freq_dict_bad.get, reverse=True)[:1000]\n",
    "    good_words = sorted(freq_dict_good, key=freq_dict_good.get, reverse=True)[:1000]\n",
    "\n",
    "    print(\"--- Generating num_bad_words\")\n",
    "    train[\"num_bad_words\"] = train[\"comment_text\"].map(lambda x: num_bad_words(x))\n",
    "    test[\"num_bad_words\"] = test[\"comment_text\"].map(lambda x: num_bad_words(x))\n",
    "\n",
    "    print(\"--- Generating num_good_words\")\n",
    "    train[\"num_good_words\"] = train[\"comment_text\"].map(lambda x: num_good_words(x))\n",
    "    test[\"num_good_words\"] = test[\"comment_text\"].map(lambda x: num_good_words(x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    \n",
    "    # Feature generation\n",
    "    \n",
    "    def gen_feats(df):\n",
    "        start_time = time.time()\n",
    "            \n",
    "        print(\"--- Generating non_eng\")\n",
    "        df[\"non_eng\"] = df[\"comment_text\"].swifter.apply(lambda x: contains_non_english(x))\n",
    "\n",
    "        print(\"--- Generating first_word\")\n",
    "        df[\"first_word\"] = df[\"comment_text\"].swifter.apply(lambda x: get_first_word(x))\n",
    "\n",
    "        print(\"--- Generating num_chars (num chars)\")\n",
    "        df['num_chars'] = df['comment_text'].swifter.apply(len)\n",
    "\n",
    "        print(\"--- Generating num_caps\")\n",
    "        df['num_caps'] = df['comment_text'].swifter.apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "\n",
    "        print(\"--- Generating caps_vs_length\")\n",
    "        get_cap_vs_length(df)\n",
    "\n",
    "        #print(\"--- Generating num_exclamation_marks\")\n",
    "        #df['num_exclamation_marks'] = df['comment_text'].apply(lambda comment: comment.count('!'))\n",
    "\n",
    "        print(\"--- Generating num_question_marks\")\n",
    "        df['num_question_marks'] = df['comment_text'].apply(lambda comment: comment.count('?'))\n",
    "\n",
    "        print(\"--- Generating num_punctuation\")\n",
    "        df['num_punctuation'] = df['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "\n",
    "        #print(\"--- Generating num_symbols\")\n",
    "        #df['num_symbols'] = df['comment_text'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n",
    "\n",
    "        print(\"--- Generating num_words\")\n",
    "        df['num_words'] = df['comment_text'].swifter.apply(lambda comment: len(re.sub(r'[^\\w\\s]','',comment).split(\" \")))\n",
    "\n",
    "        print(\"--- Generating num_unique_words\")\n",
    "        df['num_unique_words'] = df['comment_text'].swifter.apply(lambda comment: len(set(w for w in comment.split())))\n",
    "\n",
    "        print(\"--- Generating unique_word_over_num_words\")\n",
    "        get_unique_word_over_num_words(df)\n",
    "\n",
    "        #print(\"--- Generating num_smilies\")\n",
    "        #df['num_smilies'] = df['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\n",
    "\n",
    "        print(\"--- Generating num_sentences\")\n",
    "        df['num_sentences'] = df['comment_text'].swifter.apply(lambda comment: len(re.split(r'[.!?]+', comment)))\n",
    "\n",
    "        print(\"--- Generating max_word_len\")\n",
    "        df['max_word_len'] = df['comment_text'].swifter.apply(lambda comment: calc_max_word_len(re.sub(r'[^\\w\\s]','',comment).split(\" \")))\n",
    "        \n",
    "        print(\"--- Generating min_word_len\")\n",
    "        df['max_word_len'] = df['comment_text'].swifter.apply(lambda comment: calc_min_word_len(re.sub(r'[^\\w\\s]','',comment).split(\" \")))\n",
    "        \n",
    "        print(\"--- Generating total_word_length (num of chars in words)\")\n",
    "        df['total_word_length'] = df['comment_text'].swifter.apply(lambda comment: calc_total_word_len(re.sub(r'[^\\w\\s]','',comment).split(\" \")))\n",
    "        \n",
    "        print(\"--- Generating avg_word_len\")\n",
    "        get_avg_word_len(df)\n",
    "        \n",
    "        print(\"--- Generating total_unique_word_length (num of chars in words)\")\n",
    "        df['total_unique_word_length'] = df['comment_text'].swifter.apply(lambda comment: calc_total_unique_word_len(re.sub(r'[^\\w\\s]','',comment).split(\" \")))\n",
    "        \n",
    "        print(\"--- Generating avg_unique_word_len\")\n",
    "        get_avg_unique_word_len(df)\n",
    "        \n",
    "        print(\"--- Finished Gen Feats. Took %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "\n",
    "    def cleanText(df):\n",
    "        start_time = time.time()\n",
    "        df['comment_text'] = df['comment_text'].swifter.apply(lambda x: split_off_symbols_iv(x)) #increase score\n",
    "        \"\"\"print(\"--- cleaning text\")\n",
    "        df[\"comment_text\"] = df[\"comment_text\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "        print(\"--- remove single characters\")\n",
    "        df[\"comment_text\"] = df[\"comment_text\"].apply(lambda x: remove_singles(x))\n",
    "\n",
    "        print(\"--- cleaning numbers\")\n",
    "        df[\"comment_text\"] = df[\"comment_text\"].apply(lambda x: clean_numbers(x))\n",
    "\n",
    "        print(\"--- cleaning misspellings\")\n",
    "        df[\"comment_text\"] = df[\"comment_text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "\n",
    "        print(\"--- filling missing values\")\n",
    "        #clean chinese, korean, japanese characters\n",
    "        print('cleaning characters')\n",
    "        df[\"comment_text\"] = df[\"comment_text\"].map(lambda x: remove_non_english(x))\n",
    "        \n",
    "        ## fill up the missing values\n",
    "        df[\"comment_text\"].fillna(\"\").values\"\"\"\n",
    "        print(\"--- Finished cleaning text. Took %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        \n",
    "    gen_feats(data)\n",
    "    #data[\"comment_text\"] = data[\"comment_text\"].astype(str).apply(lambda x: pad_chars(x, punct))\n",
    "    cleanText(data)\n",
    "    # print(\"--- Neutralizing bad words\")\n",
    "    # neutrailize_bad_words(train,test)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing train data ...\n",
      "--- Generating non_eng\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767e284dc8c84cfeb8cc9b90c5345776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating first_word\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47cd67f13b254d18bbaf992fd4d71994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating num_chars (num chars)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dc76c90b594085ab41620f3129a0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating num_caps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1525e7b2ef074e9bafbfa6eef4b0fa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating caps_vs_length\n",
      "--- Generating num_question_marks\n",
      "--- Generating num_punctuation\n",
      "--- Generating num_words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407bd61e224b4a2c847a72922b710f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating num_unique_words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9246d8b5e546fea9da35efb9bb81c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating unique_word_over_num_words\n",
      "--- Generating num_sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7f4bffa4144bf3880b74dcdd20604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating max_word_len\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c645968316da4f0cbdea557cfb520f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating min_word_len\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c4334f206a49ce8205719b6682cbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating total_word_length (num of chars in words)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d321f0734b0c43ebb8cf01325589a2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating avg_word_len\n",
      "--- Generating total_unique_word_length (num of chars in words)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58e94270c574da3a790d82128ca59c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating avg_unique_word_len\n",
      "--- Finished Gen Feats\n",
      "--- 179.87786626815796 seconds ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17ee6749332432bb5fdd7fadcd9a86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1804874, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 74.13771867752075 seconds ---\n",
      "Preprocessing test data ...\n",
      "--- Generating non_eng\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99715f838e0e4a1892e2011f6aedca33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating first_word\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a429d9a7d1486ea75d36c0d00c9a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating num_chars (num chars)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ac80b441bc4e00bede468d0ec56fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating num_caps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873756a8e1204aad86ed0eb7c8ee9d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating caps_vs_length\n",
      "--- Generating num_question_marks\n",
      "--- Generating num_punctuation\n",
      "--- Generating num_words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3b640fc1f84fafb5bf49a3297a8c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating num_unique_words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0977e862854b7b9e2a0d02b4737710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating unique_word_over_num_words\n",
      "--- Generating num_sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2beb6f4a848422d8538efeabd1cab61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating max_word_len\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9176e3d561ef4afbb3a2cd623778ec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating min_word_len\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05978e422f59475ea680831aa6e7de93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating total_word_length (num of chars in words)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5b1f32894740459e45c22b93f8cbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating avg_word_len\n",
      "--- Generating total_unique_word_length (num of chars in words)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dde688b8134492d9253836b848ebc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating avg_unique_word_len\n",
      "--- Finished Gen Feats\n",
      "--- 10.059473037719727 seconds ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455bf3a55ac2470eaf524f41f179b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.183730363845825 seconds ---\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_hdf('../input/train.h5')\n",
    "test = pd.read_hdf('../input/test.h5')\n",
    "SMALL_DATA = False\n",
    "if (SMALL_DATA):\n",
    "    train = train[:100]\n",
    "    test = test[:100]\n",
    "\n",
    "print(\"Preprocessing train data ...\")\n",
    "x_train = preprocess(train)\n",
    "print(\"Preprocessing test data ...\")\n",
    "x_test = preprocess(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
