{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import spacy\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable progress bars when submitting\n",
    "def is_interactive():\n",
    "   return 'SHLVL' not in os.environ\n",
    "\n",
    "if not is_interactive():\n",
    "    def nop(it, *a, **k):\n",
    "        return it\n",
    "\n",
    "    tqdm = nop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAWL_EMBEDDING_PATH = '../input/crawl-300d-2M.vec'\n",
    "GLOVE_EMBEDDING_PATH = '../input/glove.840B.300d.txt'\n",
    "NUM_MODELS = 2\n",
    "LSTM_UNITS = 128\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "MAX_LEN = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()\\nspell_model = gensim.models.KeyedVectors.load_word2vec_format(\\'../input/wiki-news-300d-1M.vec\\')\\nwords = spell_model.index2word\\nw_rank = {}\\nfor i,word in enumerate(words):\\n    w_rank[word] = i\\nWORDS = w_rank\\ndel words\\ndel w_rank\\ndel spell_model\\ngc.collect()\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\\n\\n# Use fast text as vocabulary\\ndef words(text): return re.findall(r\\'\\\\w+\\', text.lower())\\ndef P(word): \\n    \"Probability of `word`.\"\\n    # use inverse of rank as proxy\\n    # returns 0 if the word isn\\'t in the dictionary\\n    return - WORDS.get(word, 0)\\ndef correction(word): \\n    \"Most probable spelling correction for word.\"\\n    return max(candidates(word), key=P)\\ndef candidates(word): \\n    \"Generate possible spelling corrections for word.\"\\n    return (known([word]) or known(edits1(word)) or [word])\\ndef known(words): \\n    \"The subset of `words` that appear in the dictionary of WORDS.\"\\n    return set(w for w in words if w in WORDS)\\ndef edits1(word):\\n    \"All edits that are one edit away from `word`.\"\\n    letters    = \\'abcdefghijklmnopqrstuvwxyz\\'\\n    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\\n    deletes    = [L + R[1:]               for L, R in splits if R]\\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\\n    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\\n    inserts    = [L + c + R               for L, R in splits for c in letters]\\n    return set(deletes + transposes + replaces + inserts)\\ndef edits2(word): \\n    \"All edits that are two edits away from `word`.\"\\n    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\\ndef singlify(word):\\n    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start_time = time.time()\n",
    "spell_model = gensim.models.KeyedVectors.load_word2vec_format('../input/wiki-news-300d-1M.vec')\n",
    "words = spell_model.index2word\n",
    "w_rank = {}\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "WORDS = w_rank\n",
    "del words\n",
    "del w_rank\n",
    "del spell_model\n",
    "gc.collect()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Use fast text as vocabulary\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "def P(word): \n",
    "    \"Probability of `word`.\"\n",
    "    # use inverse of rank as proxy\n",
    "    # returns 0 if the word isn't in the dictionary\n",
    "    return - WORDS.get(word, 0)\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or [word])\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "def singlify(word):\n",
    "    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef build_matrix(word_dict, lemma_dict, path):\\n    embed_size = 300\\n    embeddings_index = load_embeddings(path)\\n    embedding_matrix = np.zeros((len(word_dict) + 1, embed_size), dtype=np.float32)\\n    unknown_words = []\\n    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1\\n    \\n    for key in tqdm(word_dict):\\n        word = key\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = key.lower()\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = key.upper()\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = key.capitalize()\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = ps.stem(key)\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = lc.stem(key)\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = sb.stem(key)\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        word = lemma_dict[key]\\n        embedding_vector = embeddings_index.get(word)\\n        if embedding_vector is not None:\\n            embedding_matrix[word_dict[key]] = embedding_vector\\n            continue\\n        if len(key) > 1:\\n            word = correction(key)\\n            embedding_vector = embeddings_index.get(word)\\n            if embedding_vector is not None:\\n                embedding_matrix[word_dict[key]] = embedding_vector\\n                continue\\n        \\n        #Unknown word, does not exist in dictionary\\n        embedding_matrix[word_dict[key]] = unknown_vector\\n        unknown_words.append(word)\\n    return embedding_matrix, unknown_words\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def load_embeddings(path):\n",
    "    with open(path) as f:\n",
    "        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n",
    "    \n",
    "def build_matrix(word_index, path):\n",
    "    embedding_index = load_embeddings(path)\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            embedding_matrix[i] = embedding_index[word]\n",
    "        except KeyError:\n",
    "            unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "'''\n",
    "def build_matrix(word_dict, lemma_dict, path):\n",
    "    embed_size = 300\n",
    "    embeddings_index = load_embeddings(path)\n",
    "    embedding_matrix = np.zeros((len(word_dict) + 1, embed_size), dtype=np.float32)\n",
    "    unknown_words = []\n",
    "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1\n",
    "    \n",
    "    for key in tqdm(word_dict):\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = ps.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lc.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = sb.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lemma_dict[key]\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        if len(key) > 1:\n",
    "            word = correction(key)\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[word_dict[key]] = embedding_vector\n",
    "                continue\n",
    "        \n",
    "        #Unknown word, does not exist in dictionary\n",
    "        embedding_matrix[word_dict[key]] = unknown_vector\n",
    "        unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceBucketCollator():\n",
    "    def __init__(self, choose_length, sequence_index, length_index, label_index=None):\n",
    "        self.choose_length = choose_length\n",
    "        self.sequence_index = sequence_index\n",
    "        self.length_index = length_index\n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        batch = [torch.stack(x) for x in list(zip(*batch))]\n",
    "        \n",
    "        sequences = batch[self.sequence_index]\n",
    "        lengths = batch[self.length_index]\n",
    "        \n",
    "        length = self.choose_length(lengths)\n",
    "        mask = torch.arange(start=maxlen, end=0, step=-1) < length\n",
    "        padded_sequences = sequences[:, mask]\n",
    "        \n",
    "        batch[self.sequence_index] = padded_sequences\n",
    "        \n",
    "        if self.label_index is not None:\n",
    "            return [x for i, x in enumerate(batch) if i != self.label_index], batch[self.label_index]\n",
    "    \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "filepath = './model_files/checkpoint.pth'\n",
    "\n",
    "def train_model(model, train, test, loss_fn, output_dim, lr=0.001,\n",
    "                batch_size=512, n_epochs=4, n_epochs_embed=2,\n",
    "                enable_checkpoint_ensemble=True):\n",
    "    \n",
    "    train_collator = SequenceBucketCollator(lambda lengths: lengths.max(), \n",
    "                                            sequence_index=0, \n",
    "                                            length_index=1, \n",
    "                                            label_index=2)\n",
    "    \n",
    "    param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
    "    optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.6 ** epoch)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=train_collator)\n",
    "    val_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, collate_fn=train_collator)\n",
    "    all_test_preds = []\n",
    "    checkpoint_weights = [2 ** epoch for epoch in range(n_epochs)]\n",
    "    \n",
    "    best_loss = 1\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.train() #set model to train mode\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        for data in tqdm(train_loader, disable=False):\n",
    "            \n",
    "            #training loop\n",
    "            x_batch = data[:-1]\n",
    "            #print(\"First: \", x_batch[0][0])\n",
    "            #print(\"Second: \", x_batch[0][1])\n",
    "            first = x_batch[0][0]\n",
    "            second = x_batch[0][1]\n",
    "            \n",
    "            y_batch = data[-1]\n",
    "\n",
    "            y_pred = model(first, second)  #feed data into model          \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            #calculate error and adjust model params\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        #Check if loss is better than current best loss, if so, save the model\n",
    "        is_best = (avg_loss < best_loss)\n",
    "        \n",
    "        if is_best:\n",
    "            print (\"=> Saving a new best\")\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_loss': best_loss\n",
    "            }, filepath)  # save checkpoint\n",
    "        else:\n",
    "            print (\"=> Model Accuracy did not improve\")\n",
    "            \n",
    "        \n",
    "        model.eval() #set model to eval mode for test data\n",
    "        test_preds = np.zeros((len(test), output_dim))\n",
    "        \n",
    "    \n",
    "        for i, x_batch in enumerate(val_loader):\n",
    "            #print(\"X_Batch: \", x_batch)\n",
    "            data_param = x_batch[0][0]\n",
    "            lengths_param = x_batch[0][1]\n",
    "            y_pred = sigmoid(model(data_param, lengths_param).detach().cpu().numpy()) #feed data into model\n",
    "\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred #get test predictions\n",
    "        \n",
    "        #test_preds has the predictions for the entire test set now\n",
    "        all_test_preds.append(test_preds) #append predictions to the record of all past predictions\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "              epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "        \n",
    "    #Make embeddings layer only layer unfreezed, train again (literally run through the n_epochs)\n",
    "    #maybe define a n_epochs_embedding\n",
    "    \n",
    "    #parameters = model.parameters()\n",
    "    #for param in parameters:\n",
    "    #        param.requires_grad = False\n",
    "    #parameters[0].requires_grad = True\n",
    "    \n",
    "    '''\n",
    "    ct = 0\n",
    "    for child in model.children():\n",
    "        if ct == 0:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        ct += 1\n",
    "    \n",
    "    for epoch in range(n_epochs_embed):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        model.train() #set model to train mode\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        for data in tqdm(train_loader, disable=False):\n",
    "            \n",
    "            #training loop\n",
    "            x_batch = data[:-1]\n",
    "            y_batch = data[-1]\n",
    "\n",
    "            y_pred = model(*x_batch)  #feed data into model          \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            #calculate error and adjust model params\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader) #gets the loss per epoch\n",
    "        \n",
    "            \n",
    "        model.eval() #set model to eval mode for test data\n",
    "        test_preds = np.zeros((len(test), output_dim))\n",
    "    \n",
    "        for i, x_batch in enumerate(test_loader):\n",
    "            y_pred = sigmoid(model(*x_batch).detach().cpu().numpy()) #feed data into model\n",
    "\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred #get test predictions\n",
    "        \n",
    "        #test_preds has the predictions for the entire test set now\n",
    "        #all_test_preds.append(test_preds) #append predictions to the record of all past predictions\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('[EMBEDDING TRAINING] Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s '.format(\n",
    "              epoch + 1, n_epochs_embed, avg_loss, elapsed_time))\n",
    "    '''\n",
    "    \n",
    "    #PREDICTION CODE\n",
    "    '''\n",
    "    if enable_checkpoint_ensemble:\n",
    "        #if our approach is an ensemble then we average it amongst all the historical predictions\n",
    "        test_preds = np.average(all_test_preds, weights=checkpoint_weights, axis=0)    \n",
    "    else:\n",
    "        #if our approach is not an ensemble then we just take the last set of predictions\n",
    "        test_preds = all_test_preds[-1]\n",
    "        \n",
    "    return test_preds\n",
    "    '''\n",
    "    \n",
    "    #return trained model\n",
    "    return model\n",
    "\n",
    "def predict(model, test, output_dim, batch_size=512, pred_type=\"val\"):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    if pred_type == \"test\":\n",
    "        test_collator = SequenceBucketCollator(lambda lengths: lengths.max(), sequence_index=0, length_index=1)\n",
    "        test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, collate_fn=test_collator)\n",
    "\n",
    "        model.eval() #set model to eval mode for test data\n",
    "        test_preds = np.zeros((len(test), output_dim))\n",
    "\n",
    "        for i, x_batch in enumerate(test_loader):\n",
    "            #print(x_batch[0])\n",
    "            data_param = x_batch[0]\n",
    "            lengths_param = x_batch[1]\n",
    "            y_pred = sigmoid(model(data_param, lengths_param).detach().cpu().numpy()) #feed data into model\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred #get test predictions\n",
    "\n",
    "        return test_preds\n",
    "    else:\n",
    "        test_collator = SequenceBucketCollator(lambda lengths: lengths.max(), sequence_index=0, length_index=1, label_index=2)\n",
    "        test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, collate_fn=test_collator)\n",
    "\n",
    "        model.eval() #set model to eval mode for test data\n",
    "        test_preds = np.zeros((len(test), output_dim))\n",
    "\n",
    "        for i, x_batch in enumerate(test_loader):\n",
    "            #print(x_batch)\n",
    "            data_param = x_batch[0][0]\n",
    "            lengths_param = x_batch[0][1]\n",
    "            y_pred = sigmoid(model(data_param, lengths_param).detach().cpu().numpy()) #feed data into model\n",
    "            test_preds[i * batch_size:(i+1) * batch_size, :] = y_pred #get test predictions\n",
    "\n",
    "        return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        #call the forward method in Dropout2d (super function specifies the subclass and instance)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "    \n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_aux_targets):\n",
    "        #call the init mthod in Module (super function specifies the subclass and instance)\n",
    "        super(NeuralNet, self).__init__() \n",
    "        embed_size = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
    "    \n",
    "        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        \n",
    "        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n",
    "        self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x, lengths=None):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.embedding_dropout(h_embedding)\n",
    "        \n",
    "        #first variable h_(lstm #) holds the output, _ is the (hidden state, cell state)\n",
    "        h_lstm1, _ = self.lstm1(h_embedding) \n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        # global average pooling\n",
    "        avg_pool = torch.mean(h_lstm2, 1) #get the mean value of the first dimension in h_lstm2\n",
    "        # global max pooling\n",
    "        max_pool, _ = torch.max(h_lstm2, 1) #get the max value of the first dimension in h_lstm2\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
    "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def preprocess(data):\n",
    "\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    return data\n",
    "'''\n",
    "symbols_to_isolate = '.,?!-;*\"…:—()%#$&_/@＼・ω+=”“[]^–>\\\\°<~•≠™ˈʊɒ∞§{}·τα❤☺ɡ|¢→̶`❥━┣┫┗Ｏ►★©―ɪ✔®\\x96\\x92●£♥➤´¹☕≈÷♡◐║▬′ɔː€۩۞†μ✒➥═☆ˌ◄½ʻπδηλσερνʃ✬ＳＵＰＥＲＩＴ☻±♍µº¾✓◾؟．⬅℅»Вав❣⋅¿¬♫ＣＭβ█▓▒░⇒⭐›¡₂₃❧▰▔◞▀▂▃▄▅▆▇↙γ̄″☹➡«φ⅓„✋：¥̲̅́∙‛◇✏▷❓❗¶˚˙）сиʿ✨。ɑ\\x80◕！％¯−ﬂﬁ₁²ʌ¼⁴⁄₄⌠♭✘╪▶☭✭♪☔☠♂☃☎✈✌✰❆☙○‣⚓年∎ℒ▪▙☏⅛ｃａｓǀ℮¸ｗ‚∼‖ℳ❄←☼⋆ʒ⊂、⅔¨͡๏⚾⚽Φ×θ￦？（℃⏩☮⚠月✊❌⭕▸■⇌☐☑⚡☄ǫ╭∩╮，例＞ʕɐ̣Δ₀✞┈╱╲▏▕┃╰▊▋╯┳┊≥☒↑☝ɹ✅☛♩☞ＡＪＢ◔◡↓♀⬆̱ℏ\\x91⠀ˤ╚↺⇤∏✾◦♬³の｜／∵∴√Ω¤☜▲↳▫‿⬇✧ｏｖｍ－２０８＇‰≤∕ˆ⚜☁'\n",
    "symbols_to_delete = '\\n🍕\\r🐵😑\\xa0\\ue014\\t\\uf818\\uf04a\\xad😢🐶️\\uf0e0😜😎👊\\u200b\\u200e😁عدويهصقأناخلىبمغر😍💖💵Е👎😀😂\\u202a\\u202c🔥😄🏻💥ᴍʏʀᴇɴᴅᴏᴀᴋʜᴜʟᴛᴄᴘʙғᴊᴡɢ😋👏שלוםבי😱‼\\x81エンジ故障\\u2009🚌ᴵ͞🌟😊😳😧🙀😐😕\\u200f👍😮😃😘אעכח💩💯⛽🚄🏼ஜ😖ᴠ🚲‐😟😈💪🙏🎯🌹😇💔😡\\x7f👌ἐὶήιὲκἀίῃἴξ🙄Ｈ😠\\ufeff\\u2028😉😤⛺🙂\\u3000تحكسة👮💙فزط😏🍾🎉😞\\u2008🏾😅😭👻😥😔😓🏽🎆🍻🍽🎶🌺🤔😪\\x08‑🐰🐇🐱🙆😨🙃💕𝘊𝘦𝘳𝘢𝘵𝘰𝘤𝘺𝘴𝘪𝘧𝘮𝘣💗💚地獄谷улкнПоАН🐾🐕😆ה🔗🚽歌舞伎🙈😴🏿🤗🇺🇸мυтѕ⤵🏆🎃😩\\u200a🌠🐟💫💰💎эпрд\\x95🖐🙅⛲🍰🤐👆🙌\\u2002💛🙁👀🙊🙉\\u2004ˢᵒʳʸᴼᴷᴺʷᵗʰᵉᵘ\\x13🚬🤓\\ue602😵άοόςέὸתמדףנרךצט😒͝🆕👅👥👄🔄🔤👉👤👶👲🔛🎓\\uf0b7\\uf04c\\x9f\\x10成都😣⏺😌🤑🌏😯ех😲Ἰᾶὁ💞🚓🔔📚🏀👐\\u202d💤🍇\\ue613小土豆🏡❔⁉\\u202f👠》कर्मा🇹🇼🌸蔡英文🌞🎲レクサス😛外国人关系Сб💋💀🎄💜🤢َِьыгя不是\\x9c\\x9d🗑\\u2005💃📣👿༼つ༽😰ḷЗз▱ц￼🤣卖温哥华议会下降你失去所有的钱加拿大坏税骗子🐝ツ🎅\\x85🍺آإشء🎵🌎͟ἔ油别克🤡🤥😬🤧й\\u2003🚀🤴ʲшчИОРФДЯМюж😝🖑ὐύύ特殊作戦群щ💨圆明园קℐ🏈😺🌍⏏ệ🍔🐮🍁🍆🍑🌮🌯🤦\\u200d𝓒𝓲𝓿𝓵안영하세요ЖљКћ🍀😫🤤ῦ我出生在了可以说普通话汉语好极🎼🕺🍸🥂🗽🎇🎊🆘🤠👩🖒🚪天一家⚲\\u2006⚭⚆⬭⬯⏖新✀╌🇫🇷🇩🇪🇮🇬🇧😷🇨🇦ХШ🌐\\x1f杀鸡给猴看ʁ𝗪𝗵𝗲𝗻𝘆𝗼𝘂𝗿𝗮𝗹𝗶𝘇𝗯𝘁𝗰𝘀𝘅𝗽𝘄𝗱📺ϖ\\u2000үսᴦᎥһͺ\\u2007հ\\u2001ɩｙｅ൦ｌƽｈ𝐓𝐡𝐞𝐫𝐮𝐝𝐚𝐃𝐜𝐩𝐭𝐢𝐨𝐧Ƅᴨןᑯ໐ΤᏧ௦Іᴑ܁𝐬𝐰𝐲𝐛𝐦𝐯𝐑𝐙𝐣𝐇𝐂𝐘𝟎ԜТᗞ౦〔Ꭻ𝐳𝐔𝐱𝟔𝟓𝐅🐋ﬃ💘💓ё𝘥𝘯𝘶💐🌋🌄🌅𝙬𝙖𝙨𝙤𝙣𝙡𝙮𝙘𝙠𝙚𝙙𝙜𝙧𝙥𝙩𝙪𝙗𝙞𝙝𝙛👺🐷ℋ𝐀𝐥𝐪🚶𝙢Ἱ🤘ͦ💸ج패티Ｗ𝙇ᵻ👂👃ɜ🎫\\uf0a7БУі🚢🚂ગુજરાતીῆ🏃𝓬𝓻𝓴𝓮𝓽𝓼☘﴾̯﴿₽\\ue807𝑻𝒆𝒍𝒕𝒉𝒓𝒖𝒂𝒏𝒅𝒔𝒎𝒗𝒊👽😙\\u200cЛ‒🎾👹⎌🏒⛸公寓养宠物吗🏄🐀🚑🤷操美𝒑𝒚𝒐𝑴🤙🐒欢迎来到阿拉斯ספ𝙫🐈𝒌𝙊𝙭𝙆𝙋𝙍𝘼𝙅ﷻ🦄巨收赢得白鬼愤怒要买额ẽ🚗🐳𝟏𝐟𝟖𝟑𝟕𝒄𝟗𝐠𝙄𝙃👇锟斤拷𝗢𝟳𝟱𝟬⦁マルハニチロ株式社⛷한국어ㄸㅓ니͜ʖ𝘿𝙔₵𝒩ℯ𝒾𝓁𝒶𝓉𝓇𝓊𝓃𝓈𝓅ℴ𝒻𝒽𝓀𝓌𝒸𝓎𝙏ζ𝙟𝘃𝗺𝟮𝟭𝟯𝟲👋🦊多伦🐽🎻🎹⛓🏹🍷🦆为和中友谊祝贺与其想象对法如直接问用自己猜本传教士没积唯认识基督徒曾经让相信耶稣复活死怪他但当们聊些政治题时候战胜因圣把全堂结婚孩恐惧且栗谓这样还♾🎸🤕🤒⛑🎁批判检讨🏝🦁🙋😶쥐스탱트뤼도석유가격인상이경제황을렵게만들지않록잘관리해야합다캐나에서대마초와화약금의품런성분갈때는반드시허된사용🔫👁凸ὰ💲🗯𝙈Ἄ𝒇𝒈𝒘𝒃𝑬𝑶𝕾𝖙𝖗𝖆𝖎𝖌𝖍𝖕𝖊𝖔𝖑𝖉𝖓𝖐𝖜𝖞𝖚𝖇𝕿𝖘𝖄𝖛𝖒𝖋𝖂𝕴𝖟𝖈𝕸👑🚿💡知彼百\\uf005𝙀𝒛𝑲𝑳𝑾𝒋𝟒😦𝙒𝘾𝘽🏐𝘩𝘨ὼṑ𝑱𝑹𝑫𝑵𝑪🇰🇵👾ᓇᒧᔭᐃᐧᐦᑳᐨᓃᓂᑲᐸᑭᑎᓀᐣ🐄🎈🔨🐎🤞🐸💟🎰🌝🛳点击查版🍭𝑥𝑦𝑧ＮＧ👣\\uf020っ🏉ф💭🎥Ξ🐴👨🤳🦍\\x0b🍩𝑯𝒒😗𝟐🏂👳🍗🕉🐲چی𝑮𝗕𝗴🍒ꜥⲣⲏ🐑⏰鉄リ事件ї💊「」\\uf203\\uf09a\\uf222\\ue608\\uf202\\uf099\\uf469\\ue607\\uf410\\ue600燻製シ虚偽屁理屈Г𝑩𝑰𝒀𝑺🌤𝗳𝗜𝗙𝗦𝗧🍊ὺἈἡχῖΛ⤏🇳𝒙ψՁմեռայինրւդձ冬至ὀ𝒁🔹🤚🍎𝑷🐂💅𝘬𝘱𝘸𝘷𝘐𝘭𝘓𝘖𝘹𝘲𝘫کΒώ💢ΜΟΝΑΕ🇱♲𝝈↴💒⊘Ȼ🚴🖕🖤🥘📍👈➕🚫🎨🌑🐻𝐎𝐍𝐊𝑭🤖🎎😼🕷ｇｒｎｔｉｄｕｆｂｋ𝟰🇴🇭🇻🇲𝗞𝗭𝗘𝗤👼📉🍟🍦🌈🔭《🐊🐍\\uf10aლڡ🐦\\U0001f92f\\U0001f92a🐡💳ἱ🙇𝗸𝗟𝗠𝗷🥜さようなら🔼'\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "nltk_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "\n",
    "isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\n",
    "remove_dict = {ord(c):f'' for c in symbols_to_delete}\n",
    "\n",
    "\n",
    "def handle_punctuation(x):\n",
    "    x = x.translate(remove_dict)\n",
    "    x = x.translate(isolate_dict)\n",
    "    return x\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = nltk_tokenizer.tokenize(x)\n",
    "    return x\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def preprocess(x):\n",
    "    x = handle_punctuation(x)\n",
    "    x = handle_contractions(x)\n",
    "    x = fix_quote(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curtis/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "#pd.read_csv(\"P00000001-ALL.csv\", nrows=20)\n",
    "#train = pd.read_hdf('../input/train.h5')\n",
    "#test = pd.read_hdf('../input/test.h5')\n",
    "#tqdm.pandas()\n",
    "\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "x_train = train['comment_text'].apply(lambda x:preprocess(x))\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "num_train_data = y_train.shape[0]\n",
    "y_train_identity = np.where(train[identity_columns] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']]\n",
    "x_test = test['comment_text'].apply(lambda x:preprocess(x))\n",
    "y_aux_train = y_aux_train.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmax_features = None\\n\\n#Create the dictionary of all words that exist in our data\\nnlp = spacy.load(\"en_core_web_lg\", disable=[\\'parser\\',\\'ner\\',\\'tagger\\'])\\ntext_list = pd.concat([x_train, x_test])\\nnlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\\nword_dict = {}\\nlemma_dict = {}\\nword_index = 1\\ndocs = nlp.pipe(text_list, n_threads = 2)\\nword_sequences = []\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "max_features = None\n",
    "\n",
    "#Create the dictionary of all words that exist in our data\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=['parser','ner','tagger'])\n",
    "text_list = pd.concat([x_train, x_test])\n",
    "nlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\n",
    "word_dict = {}\n",
    "lemma_dict = {}\n",
    "word_index = 1\n",
    "docs = nlp.pipe(text_list, n_threads = 2)\n",
    "word_sequences = []\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart_time = time.time()\\nfor doc in tqdm(docs): #one doc is one comment(row)\\n    #print(count)\\n    word_seq = []\\n    for token in doc:\\n        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\\n            word_dict[token.text] = word_index\\n            word_index += 1\\n            lemma_dict[token.text] = token.lemma_\\n        if token.pos_ is not \"PUNCT\":\\n            word_seq.append(word_dict[token.text])\\n    word_sequences.append(word_seq)\\n    #count+= 1\\n\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\\ndel docs\\ndel text_list\\ngc.collect()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dictionary of word mapping to integers as wel as lemma dictionary\n",
    "#count = 1\n",
    "'''\n",
    "start_time = time.time()\n",
    "for doc in tqdm(docs): #one doc is one comment(row)\n",
    "    #print(count)\n",
    "    word_seq = []\n",
    "    for token in doc:\n",
    "        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\n",
    "            word_dict[token.text] = word_index\n",
    "            word_index += 1\n",
    "            lemma_dict[token.text] = token.lemma_\n",
    "        if token.pos_ is not \"PUNCT\":\n",
    "            word_seq.append(word_dict[token.text])\n",
    "    word_sequences.append(word_seq)\n",
    "    #count+= 1\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "del docs\n",
    "del text_list\n",
    "gc.collect()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 400000\n",
    "tokenizer = text.Tokenizer(num_words = max_features, filters='',lower=False)\n",
    "tokenizer.fit_on_texts(list(x_train) + list(x_test))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_features = max_features or len(word_dict) + 1\n",
    "max_features = max_features or len(tokenizer.word_index) + 1\n",
    "max_features #number of unique words there are in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n unknown words (crawl):  222943\n",
      "--- 74.586101770401 seconds ---\n",
      "Size:  (487814, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#crawl_matrix, unknown_words_crawl = build_matrix(word_dict, lemma_dict, CRAWL_EMBEDDING_PATH)\n",
    "crawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\n",
    "print('n unknown words (crawl): ', len(unknown_words_crawl))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Size: ', crawl_matrix.shape)\n",
    "del unknown_words_crawl\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n unknown words (glove):  225246\n",
      "--- 84.45934987068176 seconds ---\n",
      "Size:  (487814, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#glove_matrix, unknown_words_glove = build_matrix(word_dict, lemma_dict, GLOVE_EMBEDDING_PATH)\n",
    "glove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\n",
    "print('n unknown words (glove): ', len(unknown_words_glove))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Size: ', glove_matrix.shape)\n",
    "del unknown_words_glove\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.concatenate([crawl_matrix, glove_matrix], axis=-1)\n",
    "\n",
    "del crawl_matrix\n",
    "del glove_matrix\n",
    "#del word_dict\n",
    "#del lemma_dict\n",
    "#del WORDS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawEvaluator:\n",
    "\n",
    "    def __init__(self, y_true, y_identity, power=-5, overall_model_weight=0.25):\n",
    "        self.y = y_true\n",
    "        self.y_i = y_identity\n",
    "        self.n_subgroups = self.y_i.shape[1]\n",
    "        self.power = power\n",
    "        self.overall_model_weight = overall_model_weight\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    def _compute_subgroup_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] == 1\n",
    "        #print(self.y)\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def _compute_bpsn_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def _compute_bnsp_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y != 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "\n",
    "    def compute_bias_metrics_for_model(self, y_pred):\n",
    "        #print(y_pred)\n",
    "        records = np.zeros((3, self.n_subgroups))\n",
    "        for i in range(self.n_subgroups):\n",
    "            #print(y_pred)\n",
    "            records[0, i] = self._compute_subgroup_auc(i, y_pred)\n",
    "            records[1, i] = self._compute_bpsn_auc(i, y_pred)\n",
    "            records[2, i] = self._compute_bnsp_auc(i, y_pred)\n",
    "        return records\n",
    "\n",
    "    def _calculate_overall_auc(self, y_pred):\n",
    "        return roc_auc_score(self.y, y_pred)\n",
    "\n",
    "    def _power_mean(self, array):\n",
    "        total = sum(np.power(array, self.power))\n",
    "        return np.power(total / len(array), 1 / self.power)\n",
    "\n",
    "    def get_final_metric(self, y_pred):\n",
    "        bias_metrics = self.compute_bias_metrics_for_model(y_pred)\n",
    "        bias_score = np.average([\n",
    "            self._power_mean(bias_metrics[0]),\n",
    "            self._power_mean(bias_metrics[1]),\n",
    "            self._power_mean(bias_metrics[2])\n",
    "        ])\n",
    "        overall_score = self.overall_model_weight * self._calculate_overall_auc(y_pred)\n",
    "        bias_score = (1 - self.overall_model_weight) * bias_score\n",
    "        return overall_score + bias_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804874\n",
      "torch.Size([1804874])\n",
      "188\n",
      "tensor(713)\n"
     ]
    }
   ],
   "source": [
    "#x_train = word_sequences[:num_train_data]\n",
    "#x_test = word_sequences[num_train_data:]\n",
    "lengths = torch.from_numpy(np.array([len(x) for x in x_train]))\n",
    "test_lengths = torch.from_numpy(np.array([len(x) for x in x_test]))\n",
    "print(len(x_train))\n",
    "print(lengths.shape)\n",
    "maxlen = int(np.percentile(lengths, 95)) \n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print(maxlen)\n",
    "print(lengths.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804874, 188)\n",
      "(1804874,)\n",
      "1804874\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(num_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: PRELIM FILTER\n",
      "=> Saving a new best\n",
      "Epoch 1/4 \t loss=0.0809 \t time=655.38s\n",
      "=> Saving a new best\n",
      "Epoch 2/4 \t loss=0.0746 \t time=657.73s\n",
      "=> Saving a new best\n",
      "Epoch 3/4 \t loss=0.0735 \t time=658.63s\n",
      "=> Saving a new best\n",
      "Epoch 4/4 \t loss=0.0728 \t time=659.25s\n",
      "Kaggle Score:  0.9398711312814203\n",
      "ROC score:  0.9735292218007326\n",
      "====================== END OF FILTER =============================\n"
     ]
    }
   ],
   "source": [
    "#Here, we use one model that filters out all the easy predictions\n",
    "x_train_torch = torch.tensor(x_train, dtype=torch.long).cuda()\n",
    "y_train_torch = torch.tensor(np.hstack([y_train[:, np.newaxis], y_aux_train]), dtype=torch.float32).cuda()\n",
    "train_dataset = data.TensorDataset(x_train_torch, lengths ,y_train_torch)\n",
    "\n",
    "print('Model: PRELIM FILTER')\n",
    "seed_everything(1234)\n",
    "\n",
    "model = NeuralNet(embedding_matrix, y_aux_train.shape[-1])\n",
    "model.cuda()\n",
    "\n",
    "#training using training and validation set\n",
    "model = train_model(model, train_dataset, train_dataset, output_dim=y_train_torch.shape[-1], \n",
    "                         loss_fn=nn.BCEWithLogitsLoss(reduction='mean'))\n",
    "\n",
    "\n",
    "#prediction on entire train set\n",
    "pred = predict(model, train_dataset, output_dim=y_train_torch.shape[-1])[:,0]\n",
    "\n",
    "evaluator = JigsawEvaluator(y_train, y_train_identity)\n",
    "auc_score = evaluator.get_final_metric(pred)\n",
    "roc_score = roc_auc_score(y_train, pred)\n",
    "\n",
    "print('Kaggle Score: ', auc_score)\n",
    "print('ROC score: ', roc_score)\n",
    "\n",
    "        \n",
    "print('====================== END OF FILTER =============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEAR \n",
    "del x_train_torch\n",
    "del y_train_torch\n",
    "del train_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AND GET DISTRIBUTIONS OF PREDICTIONS\n",
    "plt.hist(pred)\n",
    "plt.title(\"Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% of comments have a score of less than 4.716167048172792e-05\n",
      "2% of comments have a score of less than 5.7090710470220074e-05\n",
      "3% of comments have a score of less than 6.539529422298074e-05\n",
      "4% of comments have a score of less than 7.316590199479833e-05\n",
      "5% of comments have a score of less than 8.071067350101657e-05\n",
      "6% of comments have a score of less than 8.820692572044208e-05\n",
      "7% of comments have a score of less than 9.578832396073267e-05\n",
      "8% of comments have a score of less than 0.00010333054960938172\n",
      "9% of comments have a score of less than 0.00011116965142718982\n",
      "10% of comments have a score of less than 0.00011926486113225112\n",
      "11% of comments have a score of less than 0.00012766249346896075\n",
      "12% of comments have a score of less than 0.00013632517249789088\n",
      "13% of comments have a score of less than 0.00014525270671583712\n",
      "14% of comments have a score of less than 0.00015454382781172172\n",
      "15% of comments have a score of less than 0.00016420407991972754\n",
      "16% of comments have a score of less than 0.00017427570826839656\n",
      "17% of comments have a score of less than 0.0001849189418135211\n",
      "18% of comments have a score of less than 0.00019609125592978674\n",
      "19% of comments have a score of less than 0.00020773560099769385\n",
      "20% of comments have a score of less than 0.0002199432346969843\n",
      "21% of comments have a score of less than 0.00023279977904167026\n",
      "22% of comments have a score of less than 0.0002465142752043903\n",
      "23% of comments have a score of less than 0.0002609371722792276\n",
      "24% of comments have a score of less than 0.0002764105261303484\n",
      "25% of comments have a score of less than 0.0002925345252151601\n",
      "26% of comments have a score of less than 0.00030935908842366215\n",
      "27% of comments have a score of less than 0.0003276766955968924\n",
      "28% of comments have a score of less than 0.0003468418051488698\n",
      "29% of comments have a score of less than 0.00036707503895740953\n",
      "30% of comments have a score of less than 0.0003890378575306386\n",
      "31% of comments have a score of less than 0.00041274267859989775\n",
      "32% of comments have a score of less than 0.0004375141556374728\n",
      "33% of comments have a score of less than 0.0004643700024462306\n",
      "34% of comments have a score of less than 0.0004930949653498828\n",
      "35% of comments have a score of less than 0.0005238182609900832\n",
      "36% of comments have a score of less than 0.0005576464463956654\n",
      "37% of comments have a score of less than 0.000593552555073984\n",
      "38% of comments have a score of less than 0.0006328939157538116\n",
      "39% of comments have a score of less than 0.0006750111375004053\n",
      "40% of comments have a score of less than 0.0007207707269117238\n",
      "41% of comments have a score of less than 0.000771115068346262\n",
      "42% of comments have a score of less than 0.000825897444738075\n",
      "43% of comments have a score of less than 0.0008844074892112986\n",
      "44% of comments have a score of less than 0.0009486901806667447\n",
      "45% of comments have a score of less than 0.0010194474889431149\n",
      "46% of comments have a score of less than 0.0010954139288514853\n",
      "47% of comments have a score of less than 0.0011781755706761028\n",
      "48% of comments have a score of less than 0.0012696176441386333\n",
      "49% of comments have a score of less than 0.0013725134427659215\n",
      "50% of comments have a score of less than 0.0014860194642096758\n",
      "51% of comments have a score of less than 0.0016101924167014653\n",
      "52% of comments have a score of less than 0.0017450046725571164\n",
      "53% of comments have a score of less than 0.0018972514662891626\n",
      "54% of comments have a score of less than 0.0020661201467737558\n",
      "55% of comments have a score of less than 0.0022539524361491203\n",
      "56% of comments have a score of less than 0.0024650495499372485\n",
      "57% of comments have a score of less than 0.002699255226179955\n",
      "58% of comments have a score of less than 0.0029667096864432092\n",
      "59% of comments have a score of less than 0.0032673595473170273\n",
      "60% of comments have a score of less than 0.0036066169384866955\n",
      "61% of comments have a score of less than 0.003982108947820962\n",
      "62% of comments have a score of less than 0.004420527275651693\n",
      "63% of comments have a score of less than 0.004913476877845823\n",
      "64% of comments have a score of less than 0.005485780164599414\n",
      "65% of comments have a score of less than 0.006136916717514395\n",
      "66% of comments have a score of less than 0.006883946079760801\n",
      "67% of comments have a score of less than 0.007761038634926082\n",
      "68% of comments have a score of less than 0.008762084655463697\n",
      "69% of comments have a score of less than 0.009933228837326166\n",
      "70% of comments have a score of less than 0.011268755700439186\n",
      "71% of comments have a score of less than 0.012858468107879162\n",
      "72% of comments have a score of less than 0.01470700699836017\n",
      "73% of comments have a score of less than 0.016905223224312066\n",
      "74% of comments have a score of less than 0.01947661701589823\n",
      "75% of comments have a score of less than 0.022557934280484915\n",
      "76% of comments have a score of less than 0.026146729215979575\n",
      "77% of comments have a score of less than 0.030391234289854747\n",
      "78% of comments have a score of less than 0.035409477353096\n",
      "79% of comments have a score of less than 0.04139949638396502\n",
      "80% of comments have a score of less than 0.048512473702430885\n",
      "81% of comments have a score of less than 0.05687040556222201\n",
      "82% of comments have a score of less than 0.06684084326028819\n",
      "83% of comments have a score of less than 0.07881968349218349\n",
      "84% of comments have a score of less than 0.09285068035125707\n",
      "85% of comments have a score of less than 0.10983802229166033\n",
      "86% of comments have a score of less than 0.1298387387394905\n",
      "87% of comments have a score of less than 0.15357289686799053\n",
      "88% of comments have a score of less than 0.18182746827602383\n",
      "89% of comments have a score of less than 0.21598361760377877\n",
      "90% of comments have a score of less than 0.2568695276975631\n",
      "91% of comments have a score of less than 0.30501440703868926\n",
      "92% of comments have a score of less than 0.3636422562599195\n",
      "93% of comments have a score of less than 0.43410396933555606\n",
      "94% of comments have a score of less than 0.5166156578063961\n",
      "95% of comments have a score of less than 0.614405676722524\n",
      "96% of comments have a score of less than 0.7230000114440913\n",
      "97% of comments have a score of less than 0.834487146139145\n",
      "98% of comments have a score of less than 0.9262879693508149\n",
      "99% of comments have a score of less than 0.9800746512413026\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 100):\n",
    "    thres = np.percentile(pred, i)\n",
    "    print('{}% of comments have a score of less than {}'.format(i, thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03767282366752625\n",
      "[ True  True  True ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#FILTER OUT ALL THE EASY COMMENTS (64th percentile)\n",
    "threshold = np.percentile(pred, 64)\n",
    "print(threshold)\n",
    "keep_index = (pred > threshold)\n",
    "print(keep_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_orig = x_train\n",
    "y_train_orig = y_train\n",
    "y_train_identity_orig = y_train_identity\n",
    "\n",
    "x_train = x_train[np.where(keep_index)]\n",
    "y_train = y_train[np.where(keep_index)]\n",
    "y_train_identity = y_train_identity[np.where(keep_index)]\n",
    "y_aux_train = y_aux_train[np.where(keep_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[np.where(keep_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle Score:  0.9041709031652599\n",
      "ROC score:  0.9217058856253003\n"
     ]
    }
   ],
   "source": [
    "evaluator = JigsawEvaluator(y_train, y_train_identity)\n",
    "auc_score = evaluator.get_final_metric(pred)\n",
    "roc_score = roc_auc_score(y_train, pred)\n",
    "\n",
    "print('Kaggle Score: ', auc_score)\n",
    "print('ROC score: ', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2798"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del pred\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered indices:  [     0      1      2 ... 649752 649753 649754]\n",
      "Filtered indices len:  [     0      1      2 ... 649752 649753 649754]\n",
      "Val indices:  [     0      9     23 ... 649734 649741 649752]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 389854 is out of bounds for axis 1 with size 389853",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9abc468e946f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtr_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Val indices: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mval_ind_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original Val Indicies: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ind_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mall_val_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 389854 is out of bounds for axis 1 with size 389853"
     ]
    }
   ],
   "source": [
    "filtered_indices = np.where(keep_index)[0]\n",
    "print(\"Filtered indices: \", filtered_indices)\n",
    "print(\"Filtered indices len: \", filtered_indices)\n",
    "all_val_preds = []\n",
    "all_test_preds = []\n",
    "num_splits = 5\n",
    "\n",
    "#Add in K fold \n",
    "random_state = 2019\n",
    "\n",
    "#K fold splits\n",
    "splits = list(StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=random_state).split(x_train,y_train))\n",
    "\n",
    "#final validation predictions\n",
    "final_val_preds = np.zeros((x_train_orig.shape[0])) #change to x train original shape\n",
    "\n",
    "#final test predictions to be stored in this var\n",
    "final_test_preds = np.zeros((x_test.shape[0]))\n",
    "\n",
    "start_time = time.time()\n",
    "for fold in range(num_splits):\n",
    "    tr_ind, val_ind = splits[fold]\n",
    "    print('Val indices: ', val_ind)\n",
    "    val_ind_orig = filtered_indices[val_ind]\n",
    "    print('Original Val Indicies: ', val_ind_orig)\n",
    "    all_val_preds = []\n",
    "    all_test_preds = []\n",
    "    #print('Training set size: ', len(tr_ind))\n",
    "    #print('Val set size: ', len(val_ind))\n",
    "    x_training = x_train[tr_ind]\n",
    "    y_training = y_train[tr_ind]\n",
    "    y_aux_training = y_aux_train[tr_ind]\n",
    "    \n",
    "    x_val = x_train[val_ind]\n",
    "    y_val = y_train[val_ind]\n",
    "    y_aux_val = y_aux_train[val_ind]\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_train_torch = torch.tensor(x_training, dtype=torch.long).cuda()\n",
    "    x_val_torch = torch.tensor(x_val, dtype=torch.long).cuda()\n",
    "    y_train_torch = torch.tensor(np.hstack([y_training[:, np.newaxis], y_aux_training]), dtype=torch.float32).cuda()\n",
    "    y_val_torch = torch.tensor(np.hstack([y_val[:, np.newaxis], y_aux_val]), dtype=torch.float32).cuda()\n",
    "    \n",
    "    x_test_torch = torch.tensor(x_test, dtype=torch.long).cuda()\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    #test_dataset = data.TensorDataset(x_test_torch, test_lengths)\n",
    "    #train_dataset = data.TensorDataset(x_train_torch, lengths, y_train_torch)\n",
    "    #val_dataset = data.TensorDataset(x_val_torch)\n",
    "\n",
    "    #train_collator = SequenceBucketCollator(lambda lengths: lengths.max(), sequence_index=0, length_index=1, label_index=2)\n",
    "    #test_collator = SequenceBucketCollator(lambda lengths: lengths.max(), sequence_index=0, length_index=1)\n",
    "    \n",
    "    ####\n",
    "    train_dataset = data.TensorDataset(x_train_torch, lengths[tr_ind], y_train_torch)\n",
    "    val_dataset = data.TensorDataset(x_val_torch, lengths[val_ind], y_val_torch)\n",
    "    test_dataset = data.TensorDataset(x_test_torch, test_lengths)\n",
    "    \n",
    "    #temp_dataset = data.Subset(train_dataset, indices=[0, 1])\n",
    "\n",
    "    for model_idx in range(NUM_MODELS):\n",
    "        print('Model ', model_idx)\n",
    "        seed_everything(1234 + model_idx)\n",
    "\n",
    "        model = NeuralNet(embedding_matrix, y_aux_train.shape[-1])\n",
    "        model.cuda()\n",
    "\n",
    "        #training using training and validation set\n",
    "        model = train_model(model, train_dataset, val_dataset, output_dim=y_train_torch.shape[-1], loss_fn=nn.BCEWithLogitsLoss(reduction='mean'))\n",
    "        \n",
    "        #prediction on validation set (used for score measurement)\n",
    "        val_pred = predict(model, val_dataset, output_dim=y_train_torch.shape[-1], pred_type=\"val\") #val preds on the val split\n",
    "        all_val_preds.append(val_pred)\n",
    "        #print(len(val_pred))\n",
    "        \n",
    "        #prediction on entire test set (actual predictions to be submitted)\n",
    "        test_pred = predict(model, test_dataset, output_dim=y_train_torch.shape[-1], pred_type=\"test\")\n",
    "        all_test_preds.append(test_pred)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    #average validation prediction amongst all models\n",
    "    avg_val = np.mean(all_val_preds, axis=0)[:, 0] #will be printed out per split\n",
    "    final_val_preds[val_ind_orig] += avg_val\n",
    "    \n",
    "    avg_test = np.mean(all_test_preds, axis=0)[:, 0]\n",
    "    \n",
    "    final_test_preds += avg_test #get all test scores for every split (will be averaged out at the end)\n",
    "\n",
    "    y_true = y_train[val_ind] #true scores for this validation set\n",
    "    y_identity = y_train_identity[val_ind] #true scores for the identity groups for this validation set\n",
    "    evaluator = JigsawEvaluator(y_true, y_identity)\n",
    "    auc_score = evaluator.get_final_metric(avg_val)\n",
    "\n",
    "    roc_score = roc_auc_score(y_train[val_ind], avg_val)\n",
    "    print('Kaggle Score: ', auc_score)\n",
    "    print('ROC score: ', roc_score)\n",
    "    \n",
    "    del x_train_torch\n",
    "    del x_val_torch\n",
    "    del y_train_torch\n",
    "    del y_val_torch\n",
    "    del x_test_torch\n",
    "    del train_dataset\n",
    "    del val_dataset\n",
    "    del test_dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print('=============End-of-Fold================')\n",
    "    \n",
    "end_time = time.time()\n",
    "print('Time: ', end_time - start_time)\n",
    "\n",
    "#Final combined score\n",
    "y_true = y_train_orig #y train original\n",
    "y_identity = y_train_identity_orig #y train identity original\n",
    "evaluator = JigsawEvaluator(y_true, y_identity)\n",
    "auc_score = evaluator.get_final_metric(final_val_preds)\n",
    "print('Final Kaggle Score: ', auc_score)\n",
    "print('Final ROC score: ', roc_auc_score(y_train_orig, final_val_preds))\n",
    "\n",
    "#average test predictions AGAIN this time by number of splits\n",
    "final_test_preds /= num_splits\n",
    "#print(final_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef threshold_search(y_true, y_identity, y_proba):\\n    best_threshold = 0\\n    best_score = 0\\n    for threshold in [i * 0.01 for i in range(100)]:\\n        evaluator = JigsawEvaluator(y_true, y_identity)\\n        score = evaluator.get_final_metric(y_proba > threshold)\\n        print(\"Threshold: {} , Score: {} \".format(threshold, score))\\n        if score > best_score:\\n            best_threshold = threshold\\n            best_score = score\\n    search_result = {\\'threshold\\': best_threshold, \\'kaggle_score\\': best_score}\\n    return search_result\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def threshold_search(y_true, y_identity, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in [i * 0.01 for i in range(100)]:\n",
    "        evaluator = JigsawEvaluator(y_true, y_identity)\n",
    "        score = evaluator.get_final_metric(y_proba > threshold)\n",
    "        print(\"Threshold: {} , Score: {} \".format(threshold, score))\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'kaggle_score': best_score}\n",
    "    return search_result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'threshold = threshold_search(y_true, y_identity, final_val_preds)\\nprint(threshold)\\nthres_diff = 0.5 - threshold[\"threshold\"]\\nprint(\"Threshold difference: \", thres_diff)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''threshold = threshold_search(y_true, y_identity, final_val_preds)\n",
    "print(threshold)\n",
    "thres_diff = 0.5 - threshold[\"threshold\"]\n",
    "print(\"Threshold difference: \", thres_diff)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.020993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.004992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000002</td>\n",
       "      <td>0.018071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000003</td>\n",
       "      <td>0.009714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000004</td>\n",
       "      <td>0.976520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "0  7000000    0.020993\n",
       "1  7000001    0.004992\n",
       "2  7000002    0.018071\n",
       "3  7000003    0.009714\n",
       "4  7000004    0.976520"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test['id'],\n",
    "    'prediction': final_test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
