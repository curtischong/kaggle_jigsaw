{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from torch.utils import data\n",
    "import math\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input/nvidiaapex/repository/NVIDIA-apex-39e153a\"))\n",
    "#print(os.listdir(\"../input/glove-global-vectors-for-word-representation\"))\n",
    "#print(os.listdir(\"../input/jigsaw-unintended-bias-in-toxicity-classification\"))\n",
    "#print(os.listdir(\"../input/fasttext-crawl-300d-2m\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/curtis/miniconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py:244: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-esy63wux\n",
      "Created temporary directory: /tmp/pip-req-tracker-q2h04sdm\n",
      "Created requirements tracker '/tmp/pip-req-tracker-q2h04sdm'\n",
      "Created temporary directory: /tmp/pip-install-xxpbb036\n",
      "Processing /home/curtis/Desktop/kaggle/jigsaw/input/NVIDIA-apex-39e153a\n",
      "  Created temporary directory: /tmp/pip-req-build-n_xar9df\n",
      "  Added file:///home/curtis/Desktop/kaggle/jigsaw/input/NVIDIA-apex-39e153a to build tracker '/tmp/pip-req-tracker-q2h04sdm'\n",
      "    Running setup.py (path:/tmp/pip-req-build-n_xar9df/setup.py) egg_info for package from file:///home/curtis/Desktop/kaggle/jigsaw/input/NVIDIA-apex-39e153a\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.1.0\n",
      "    running egg_info\n",
      "    creating pip-egg-info/apex.egg-info\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-n_xar9df has version 0.1, which satisfies requirement apex==0.1 from file:///home/curtis/Desktop/kaggle/jigsaw/input/NVIDIA-apex-39e153a\n",
      "  Removed apex==0.1 from file:///home/curtis/Desktop/kaggle/jigsaw/input/NVIDIA-apex-39e153a from build tracker '/tmp/pip-req-tracker-q2h04sdm'\n",
      "Skipping bdist_wheel for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Found existing installation: apex 0.1\n",
      "    Uninstalling apex-0.1:\n",
      "      Created temporary directory: /tmp/pip-uninstall-v6598cp3\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so\n",
      "      Created temporary directory: /home/curtis/miniconda3/lib/python3.7/site-packages/~pex-0.1-py3.7.egg-info\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/apex-0.1-py3.7.egg-info\n",
      "      Created temporary directory: /home/curtis/miniconda3/lib/python3.7/site-packages/~pex\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/apex/\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/fused_adam_cuda.cpython-37m-x86_64-linux-gnu.so\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
      "      Removing file or directory /home/curtis/miniconda3/lib/python3.7/site-packages/syncbn.cpython-37m-x86_64-linux-gnu.so\n",
      "      Successfully uninstalled apex-0.1\n",
      "  Created temporary directory: /tmp/pip-record-uzy76hke\n",
      "    Running command /home/curtis/miniconda3/bin/python -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-req-build-n_xar9df/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-uzy76hke/install-record.txt --single-version-externally-managed --compile\n",
      "    torch.__version__  =  1.1.0\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "    Built on Fri_Feb__8_19:08:17_PST_2019\n",
      "    Cuda compilation tools, release 10.1, V10.1.105\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "\n",
      "    Warning:  Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.\n",
      "\n",
      "    Pytorch binaries were compiled with Cuda 10.0.130\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.7\n",
      "    creating build/lib.linux-x86_64-3.7/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
      "    creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.7/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.7/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
      "    running build_ext\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.7\n",
      "    creating build/temp.linux-x86_64-3.7/csrc\n",
      "    gcc -pthread -B /home/curtis/miniconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/TH -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/THC -I/home/curtis/miniconda3/include/python3.7m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    g++ -pthread -shared -B /home/curtis/miniconda3/compiler_compat -L/home/curtis/miniconda3/lib -Wl,-rpath=/home/curtis/miniconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    gcc -pthread -B /home/curtis/miniconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/TH -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/curtis/miniconda3/include/python3.7m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "    /usr/local/cuda/bin/nvcc -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/TH -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/curtis/miniconda3/include/python3.7m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/TH -I/home/curtis/miniconda3/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/curtis/miniconda3/include/python3.7m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "^C\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hcanceled\n",
      "Cleaning up...\n",
      "  Removing source in /tmp/pip-req-build-n_xar9df\n",
      "Removed build tracker '/tmp/pip-req-tracker-q2h04sdm'\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Exception information:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 178, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 414, in run\n",
      "    use_user_site=options.use_user_site,\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/pip/_internal/req/__init__.py\", line 58, in install_given_reqs\n",
      "    **kwargs\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 951, in install\n",
      "    spinner=spinner,\n",
      "  File \"/home/curtis/miniconda3/lib/python3.7/site-packages/pip/_internal/utils/misc.py\", line 740, in call_subprocess\n",
      "    line = console_to_str(proc.stdout.readline())\n",
      "KeyboardInterrupt\n",
      "1 location(s) to search for versions of pip:\n",
      "* https://pypi.org/simple/pip/\n",
      "Getting page https://pypi.org/simple/pip/\n",
      "Starting new HTTPS connection (1): pypi.org:443\n",
      "https://pypi.org:443 \"GET /simple/pip/ HTTP/1.1\" 200 11244\n",
      "Analyzing links from page https://pypi.org/simple/pip/\n"
     ]
    }
   ],
   "source": [
    "# Installing Nvidia Apex\n",
    "#This line is for Kaggle:\n",
    "#! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a\n",
    "\n",
    "#On Cicero it should be this:\n",
    "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/NVIDIA-apex-39e153a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7b374063ae1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'once'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import pkg_resources\n",
    "import seaborn as sns\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import gc\n",
    "import re\n",
    "import operator \n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pickle\n",
    "from apex import amp\n",
    "import shutil\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 220\n",
    "SEED = 1234\n",
    "EPOCHS = 1\n",
    "Data_dir=\"../input\"\n",
    "Input_dir = \"../input\"\n",
    "WORK_DIR = \"../working/\"\n",
    "TOXICITY_COLUMN = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Bart Pytorch repo to the PATH\n",
    "# using files from: https://github.com/huggingface/pytorch-pretrained-BERT\n",
    "\n",
    "#On Kaggle it is:\n",
    "#package_dir_a = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\n",
    "\n",
    "#Oncicero it is:\n",
    "package_dir_a = \"../input/pytorch-pretrained-BERT\"\n",
    "\n",
    "sys.path.insert(0, package_dir_a)\n",
    "\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate model from tensorflow to pytorch\n",
    "\n",
    "#On Kaggle:\n",
    "#BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\n",
    "\n",
    "#On Cicero:\n",
    "BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_L-12_H-768_A-12/'\n",
    "\n",
    "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "    BERT_MODEL_PATH + 'bert_model.ckpt',\n",
    "BERT_MODEL_PATH + 'bert_config.json',\n",
    "WORK_DIR + 'pytorch_model.bin')\n",
    "\n",
    "shutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Bert configuration file\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "#On Kaggle:\n",
    "#bert_config = BertConfig('../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'+'bert_config.json')\n",
    "\n",
    "#On Cicero:\n",
    "bert_config = BertConfig('../input/bert-pretrained-models/uncased_L-12_H-768_A-12/'+'bert_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the lines to BERT format\n",
    "# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\n",
    "def convert_lines(example, max_seq_length,tokenizer):\n",
    "    max_seq_length -=2\n",
    "    all_tokens = []\n",
    "    longer = 0\n",
    "    for text in tqdm_notebook(example):\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        if len(tokens_a)>max_seq_length:\n",
    "            first = int(math.ceil(max_seq_length * 0.25)) #first 25%\n",
    "            last = max_seq_length - first\n",
    "            tokens_first = tokens_a[:first]\n",
    "            tokens_last = tokens_a[-last:]\n",
    "            tokens_a = tokens_first + tokens_last\n",
    "            longer += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
    "       \n",
    "        all_tokens.append(one_token)\n",
    "    print(\"Number of sequences longer: \", longer)\n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
    "train_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\"))\n",
    "\n",
    "train_df = train_df.sample(len(train_df),random_state=SEED)\n",
    "print('loaded %d records' % len(train_df))\n",
    "\n",
    "# Make sure all comment_text values are strings\n",
    "train_df['comment_text'] = train_df['comment_text'].astype(str) \n",
    "\n",
    "sequences = convert_lines(train_df[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\n",
    "train_df=train_df.fillna(0)\n",
    "# List all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "y_columns=['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit']\n",
    "difficult_cols = ['muslim', 'white', 'homosexual_gay_or_lesbian', 'black']\n",
    "\n",
    "print(\"wtf1\")\n",
    "\n",
    "y_aux_train = train_df[identity_columns]\n",
    "\n",
    "# Overall\n",
    "weights = np.ones((len(train_df),)) * 0.25\n",
    "# Subgroup\n",
    "weights += (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) * 0.25\n",
    "\n",
    "# Background Positive, Subgroup Negative\n",
    "weights += (( (train_df['target'].values>=0.5).astype(bool).astype(np.int) +\n",
    "   (train_df[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) * 0.25\n",
    "# Background Negative, Subgroup Positive\n",
    "weights += (( (train_df['target'].values<0.5).astype(bool).astype(np.int) +\n",
    "   (train_df[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(bool).astype(np.int) ) > 1 ).astype(bool).astype(np.int) * 0.25\n",
    "loss_weight = 1.0 / weights.mean()\n",
    "\n",
    "print(\"wtf2\")\n",
    "\n",
    "train_df = train_df.drop(['comment_text'],axis=1)\n",
    "# convert target to 0,1\n",
    "#train_df['target']=(train_df['target']>=0.5).astype(float)\n",
    "print(\"wtf3\")\n",
    "#train_df['target'] = np.vstack([(train_df['target'].values>=0.5).astype(float),weights]).T\n",
    "train_df['target']=(train_df['target']>=0.5).astype(float)\n",
    "print(\"Target: \", train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences\n",
    "y = train_df[y_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_torch = torch.tensor(X,dtype=torch.long)\n",
    "y_train_torch = torch.tensor(y,dtype=torch.float)\n",
    "full_train_dataset = torch.utils.data.TensorDataset(x_train_torch, y_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LenMatchBatchSampler(data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            count_zeros = torch.sum(self.sampler.data_source[idx][0] == 0)\n",
    "            count_zeros = int(count_zeros / 64) \n",
    "            if len(buckets[count_zeros]) == 0:  buckets[count_zeros] = []\n",
    "\n",
    "            buckets[count_zeros].append(idx)\n",
    "\n",
    "            if len(buckets[count_zeros]) == self.batch_size:\n",
    "                batch = list(buckets[count_zeros])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[count_zeros] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "        assert len(self) == yielded, \"produced an inccorect number of batches. expected %i, but yielded %i\" %(len(self), yielded)\n",
    "\n",
    "def trim_tensors(tsrs):\n",
    "    max_len = torch.max(torch.sum( (tsrs[0] != 0  ), 1))\n",
    "    if max_len > 2: \n",
    "        tsrs = [tsr[:, :max_len] for tsr in tsrs]\n",
    "    return tsrs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(data, targets):\n",
    "    ''' Define custom loss function for weighted BCE on 'target' column '''\n",
    "    #print(\"Data shape: \", data.shape)\n",
    "    #print(\"Target shape: \", targets.shape)\n",
    "    bce_loss_1 = nn.BCEWithLogitsLoss(weight=targets[:,1:2])(data[:,:1],targets[:,:1])\n",
    "    bce_loss_2 = nn.BCEWithLogitsLoss()(data[:,1:],targets[:,1:])\n",
    "    return (bce_loss_1 * loss_weight) + bce_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "NUM_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits = NUM_SPLITS, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"bert_pytorch.bin\"\n",
    "\n",
    "lr=2e-5\n",
    "batch_size = 32\n",
    "accumulation_steps=2\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"../working\",cache_dir=None,num_labels=len(y_columns))\n",
    "model.zero_grad()\n",
    "model = model.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "tq = tqdm_notebook(range(EPOCHS))\n",
    "#nm = tqdm_notebook(range(NUM_MOLDS))\n",
    "\n",
    "bert_preds = np.zeros((len(full_train_dataset)))\n",
    "for fold, (trn_idxs, val_idxs) in enumerate(skf.split(x_train_torch,y_train_torch[:,0])):\n",
    "    train_dataset = full_train_dataset[trn_idxs]\n",
    "    validation_x = full_train_dataset[val_idxs]\n",
    "    \n",
    "    num_train_optimization_steps = int(EPOCHS*len(train_dataset)/batch_size/accumulation_steps)\n",
    "\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=lr,\n",
    "                         warmup=0.05,\n",
    "                         t_total=num_train_optimization_steps)\n",
    "\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "    print(model)\n",
    "    model=model.train()\n",
    "    print(model)\n",
    "    print(\"DOUBLE CHECK MODEL IS NOT NONE\")\n",
    "\n",
    "    for epoch in tq:\n",
    "        avg_loss = 0.\n",
    "        avg_accuracy = 0.\n",
    "        lossf=None\n",
    "\n",
    "        ran_sampler = data.RandomSampler(train_dataset)\n",
    "        len_sampler = LenMatchBatchSampler(ran_sampler, batch_size = 32, drop_last = False)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler = len_sampler) \n",
    "\n",
    "        tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "        optimizer.zero_grad() \n",
    "        for i, batch in tk0:\n",
    "            #print(batch)\n",
    "            tsrs = trim_tensors(batch)\n",
    "            x_batch, y_batch = tuple(t.to(device) for t in tsrs)\n",
    "\n",
    "            y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
    "            loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "            if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "                optimizer.step()                            # Now we can do an optimizer step\n",
    "                optimizer.zero_grad()\n",
    "            if lossf:\n",
    "                lossf = 0.98*lossf+0.02*loss.item()\n",
    "            else:\n",
    "                lossf = loss.item()\n",
    "            tk0.set_postfix(loss = lossf)\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>=0.5) == (y_batch[:,0]>=0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
    "        tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n",
    "\n",
    "    # predicting on the validation set\n",
    "    model.eval()\n",
    "    validation_preds = np.zeros((len(validation_x)))\n",
    "    validation = torch.utils.data.TensorDataset(torch.tensor(validation_x, dtype=torch.long))\n",
    "    validation_loader = torch.utils.data.DataLoader(validation, batch_size=32, shuffle=False)\n",
    "    tk0 = tqdm(validation_loader)\n",
    "    for i, (x_batch,) in enumerate(tk0):\n",
    "        pred = model(x_batch.to(device), attention_mask=(x_batch > 0).to(device), labels=None)\n",
    "        validation_preds[i * 32:(i + 1) * 32] = pred[:, 0].detach().cpu().squeeze().numpy()\n",
    "    bert_preds[val_idxs] = validation_preds\n",
    "    \n",
    "    # saving a backup of the current fold's predictions\n",
    "    np.save('bert_stacking_train_preds_' +  str(fold)+ '.npy', new_train)\n",
    "    \n",
    "    # save the model\n",
    "    model_name = \"bert_\" + str(fold) + \".bin\"\n",
    "    torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once all the folds are done bert_preds should have the preds from all the validations\n",
    "\n",
    "new_train = np.c_[bert_preds, y]\n",
    "np.save('bert_stacking_train.npy', new_train) # save\n",
    "#new_num_arr = np.load('data.npy') # load\n",
    "\n",
    "\"\"\"bert_train = pd.DataFrame({bert_preds\n",
    "                           \n",
    "bert_train = pd.DataFrame.from_dict({\n",
    "    'id': test['id'],\n",
    "    'prediction': np.mean(all_test_preds, axis=0)[:, 0]\n",
    "})\n",
    "\n",
    "submission.to_hdf('submission.csv', index=False)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
