{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION SUMMARY\n",
    "\n",
    "# version 6: small bugfix\n",
    "# version 5: added example for tokenization and prediction\n",
    "# version 4: added apex install for mixed precision training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 (optional). install apex for mixed presicion support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pip/_internal/commands/install.py:207: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\r\n",
      "  cmdoptions.check_install_build_global(options)\r\n",
      "Processing /kaggle/input/apex-master/apex-master/apex-master\r\n",
      "Installing collected packages: apex\r\n",
      "  Running setup.py install for apex ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25hSuccessfully installed apex-0.1\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../input/apex-master/apex-master/apex-master/ && pip install --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pip install pytorch-pretrained-bert without internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('pip install --no-index --find-links=\"../input/pytorchpretrainedbert/\" pytorch_pretrained_bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "BERT_FP = '../input/torch-bert-weights/bert-base-uncased/bert-base-uncased/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. create BERT model and put on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained(BERT_FP).cuda()\n",
    "bert.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(vocab_file='../input/torch-bert-weights/bert-base-uncased-vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'dieter',\n",
       " 'and',\n",
       " 'i',\n",
       " 'like',\n",
       " 'wearing',\n",
       " 'my',\n",
       " 'yellow',\n",
       " 'pg',\n",
       " '##lastic',\n",
       " 'hat',\n",
       " 'while',\n",
       " 'coding',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets tokenize some text (I intentionally mispelled 'plastic' to check berts subword information handling)\n",
    "text = 'hi my name is Dieter and I like wearing my yellow pglastic hat while coding.'\n",
    "tokens = tokenizer.tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 7632,\n",
       " 2026,\n",
       " 2171,\n",
       " 2003,\n",
       " 27976,\n",
       " 1998,\n",
       " 1045,\n",
       " 2066,\n",
       " 4147,\n",
       " 2026,\n",
       " 3756,\n",
       " 18720,\n",
       " 28723,\n",
       " 6045,\n",
       " 2096,\n",
       " 16861,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# added start and end token and convert to ids\n",
    "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[ 0.0687,  0.0265, -0.2058,  ...,  0.2069, -0.1011, -0.0442],\n",
       "           [ 0.2943, -0.5316,  0.5222,  ..., -0.4604, -0.2933, -0.8875],\n",
       "           [ 0.2012,  0.5539, -0.7429,  ..., -1.3243,  0.4854, -0.2764],\n",
       "           ...,\n",
       "           [ 1.3986,  0.2449,  0.3170,  ...,  0.8570, -0.0756, -0.0035],\n",
       "           [-0.1987,  0.2619,  0.0311,  ...,  0.4481, -0.1807,  0.3393],\n",
       "           [-0.1851,  0.0641, -0.0412,  ..., -0.0486,  0.0755, -0.1101]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[-0.0126, -0.2542, -0.3644,  ...,  0.3059,  0.0251, -0.0566],\n",
       "           [ 0.6743, -0.1612,  1.0591,  ..., -0.0583,  0.0757, -1.3226],\n",
       "           [ 0.2076,  0.2962, -0.4196,  ..., -0.9514,  0.6205, -0.5414],\n",
       "           ...,\n",
       "           [ 1.8828, -0.0887,  0.2906,  ...,  1.2699, -0.0794, -0.2816],\n",
       "           [-0.2364,  0.0968,  0.2366,  ...,  0.0532, -0.2873,  0.3852],\n",
       "           [-0.2301, -0.1536,  0.1353,  ..., -0.0651,  0.1175, -0.3021]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.0087, -0.2840, -0.1869,  ...,  0.3359,  0.1131,  0.1051],\n",
       "           [ 0.7514,  0.0713,  1.2517,  ...,  0.1362, -0.4792, -1.2900],\n",
       "           [-0.0259, -0.2657, -0.1873,  ..., -0.4135,  0.4372, -0.1346],\n",
       "           ...,\n",
       "           [ 1.9307, -0.0818,  0.1208,  ...,  0.9321,  0.0849, -0.2457],\n",
       "           [-0.2479,  0.1332,  0.2711,  ...,  0.0184, -0.2878,  0.0887],\n",
       "           [-0.0844, -0.1017,  0.1198,  ...,  0.0457,  0.0320, -0.0562]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.1263, -0.6945, -0.4951,  ...,  0.3676,  0.2878,  0.4688],\n",
       "           [ 0.9790, -0.0821,  1.5124,  ...,  0.4215, -0.6608, -1.1182],\n",
       "           [ 0.0084,  0.0079, -0.2945,  ...,  0.2830,  0.1295, -0.0571],\n",
       "           ...,\n",
       "           [ 2.2279, -0.1540,  0.0596,  ...,  0.6610, -0.1909, -0.0400],\n",
       "           [-0.2583,  0.2060,  0.2658,  ..., -0.0372, -0.3905,  0.1283],\n",
       "           [-0.0190, -0.0634,  0.0204,  ...,  0.0106,  0.0523, -0.0332]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.0199, -0.7127, -0.3285,  ...,  0.0434,  0.2683,  0.5928],\n",
       "           [ 1.0679,  0.1091,  1.1861,  ...,  0.7897, -0.4209, -1.0425],\n",
       "           [ 0.0960,  0.4092, -0.2628,  ...,  0.3774, -0.1372,  0.3836],\n",
       "           ...,\n",
       "           [ 2.4771, -0.3109,  0.0415,  ...,  0.3455, -0.0115, -0.1482],\n",
       "           [ 0.1101,  0.2940,  0.1245,  ..., -0.1040, -0.1689,  0.2237],\n",
       "           [-0.0214, -0.0453,  0.0246,  ...,  0.0203,  0.0190, -0.0238]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.0784, -1.1231, -0.2800,  ...,  0.0535,  0.4380,  0.4629],\n",
       "           [ 0.8124,  0.2288,  1.1449,  ...,  0.7459, -0.4388, -1.1044],\n",
       "           [-0.3246,  0.0984, -0.2829,  ...,  0.5779, -0.1988,  0.6724],\n",
       "           ...,\n",
       "           [ 1.9676, -0.5129,  0.0593,  ...,  0.4598, -0.3103, -0.4412],\n",
       "           [-0.0456,  0.2147, -0.0178,  ..., -0.1171, -0.2549,  0.2511],\n",
       "           [ 0.0069, -0.0547, -0.0108,  ...,  0.0052, -0.0127, -0.0433]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.2241, -0.5052, -0.3829,  ..., -0.2370,  0.8108,  0.4131],\n",
       "           [ 0.5813,  0.1543,  1.1460,  ...,  0.9922, -0.1863, -1.4908],\n",
       "           [-0.5471, -0.3006, -0.2307,  ...,  0.3141,  0.8499,  0.9104],\n",
       "           ...,\n",
       "           [ 1.8700, -0.7920,  0.0712,  ...,  0.2234, -0.1323, -0.5993],\n",
       "           [-0.0644, -0.0123, -0.4382,  ..., -0.4495,  0.6435,  0.3861],\n",
       "           [ 0.0105, -0.0072, -0.0179,  ..., -0.0204,  0.0324, -0.0543]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.2417, -0.3961, -0.4872,  ..., -0.2710,  0.6095,  0.5512],\n",
       "           [ 0.6112,  0.5297,  0.8172,  ...,  0.4624, -0.1226, -1.1711],\n",
       "           [-0.5503, -0.3490, -0.1845,  ...,  0.4027,  0.5094,  0.8203],\n",
       "           ...,\n",
       "           [ 1.5442, -0.5904, -0.1491,  ...,  0.2626, -0.0776, -0.8434],\n",
       "           [-0.4803, -0.1883, -0.9442,  ..., -0.4396,  0.1828,  0.2145],\n",
       "           [ 0.0277,  0.0046,  0.0249,  ..., -0.0128, -0.0170, -0.0664]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[-0.0387, -0.1743, -0.3165,  ...,  0.0734,  0.4645,  0.2852],\n",
       "           [ 0.5099,  0.6187,  0.7278,  ..., -0.1076, -0.0847, -0.7499],\n",
       "           [-0.6254, -0.1578,  0.0723,  ...,  0.1731,  0.3614,  0.4230],\n",
       "           ...,\n",
       "           [ 1.2411, -0.4880, -0.3179,  ...,  0.1695, -0.0068, -0.7326],\n",
       "           [-0.3902,  0.3907, -0.6690,  ..., -0.5989, -0.2604, -0.3075],\n",
       "           [-0.0066,  0.0082,  0.0169,  ..., -0.0519, -0.0214, -0.0667]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[-2.0533e-01, -4.1536e-01, -1.5509e-01,  ..., -1.1564e-01,\n",
       "             1.4826e-01,  3.0875e-01],\n",
       "           [ 3.5252e-01, -6.6049e-02,  8.5435e-01,  ..., -5.6521e-01,\n",
       "             2.0840e-01, -4.4696e-01],\n",
       "           [-4.6858e-01, -1.4995e-01,  3.4006e-01,  ..., -6.0484e-01,\n",
       "             6.2571e-01, -5.1088e-01],\n",
       "           ...,\n",
       "           [ 1.2320e+00, -5.9198e-01, -6.2225e-01,  ...,  4.6859e-01,\n",
       "            -2.4479e-01, -6.8932e-01],\n",
       "           [ 6.1632e-04,  1.5398e-02, -7.8018e-02,  ..., -3.7752e-02,\n",
       "            -6.8499e-04, -1.2172e-02],\n",
       "           [ 3.0513e-02, -5.6465e-02,  1.4846e-01,  ...,  4.5660e-02,\n",
       "             1.0565e-01, -4.0775e-02]]], device='cuda:0',\n",
       "         grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.1198, -0.1454,  0.1687,  ..., -0.2964,  0.1831,  0.2246],\n",
       "           [ 0.7130,  0.0716,  0.4708,  ..., -0.5106,  1.0309, -0.5815],\n",
       "           [-0.3363,  0.0541,  0.0357,  ..., -0.5221,  0.7992,  0.1179],\n",
       "           ...,\n",
       "           [ 1.4641, -0.0949, -0.3856,  ...,  0.1537, -0.2175,  0.0623],\n",
       "           [ 0.0455,  0.0321, -0.0368,  ...,  0.0255, -0.0308,  0.0111],\n",
       "           [ 0.0366,  0.0221, -0.0280,  ...,  0.0274, -0.0340,  0.0182]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>),\n",
       "  tensor([[[ 0.2558,  0.2672,  0.1093,  ..., -0.2405,  0.5021,  0.6887],\n",
       "           [ 0.5546,  0.1027,  0.0363,  ..., -0.0206,  1.1465, -0.0422],\n",
       "           [-0.1316, -0.0343, -0.3623,  ..., -0.1227,  0.2480,  0.0849],\n",
       "           ...,\n",
       "           [ 1.1437, -0.1229, -0.2549,  ...,  0.0101,  0.0421,  0.2879],\n",
       "           [ 0.7616,  0.0504, -0.2518,  ...,  0.1949, -0.4078, -0.0716],\n",
       "           [ 0.7590,  0.1477, -0.1419,  ...,  0.1592, -0.5102, -0.0231]]],\n",
       "         device='cuda:0', grad_fn=<FusedLayerNormAffineFunction>)],\n",
       " tensor([[-0.7898, -0.5984, -0.9840,  0.7623,  0.8656, -0.2445,  0.8054,  0.3479,\n",
       "          -0.9116, -1.0000, -0.4020,  0.9744,  0.9656,  0.8161,  0.8807, -0.7143,\n",
       "          -0.3907, -0.6075,  0.3580,  0.2748,  0.7417,  1.0000, -0.1105,  0.4340,\n",
       "           0.5411,  0.9957, -0.8355,  0.8936,  0.9395,  0.7107, -0.6069,  0.3629,\n",
       "          -0.9892, -0.2520, -0.9818, -0.9849,  0.5445, -0.6231, -0.1287, -0.0167,\n",
       "          -0.8905,  0.4304,  1.0000, -0.5602,  0.5306, -0.3620, -1.0000,  0.3968,\n",
       "          -0.8117,  0.9616,  0.9379,  0.9541,  0.2428,  0.4792,  0.5449, -0.2575,\n",
       "           0.0175,  0.1314, -0.3322, -0.5724, -0.7234,  0.5302, -0.9344, -0.7944,\n",
       "           0.9540,  0.9465, -0.3070, -0.3898, -0.1925,  0.0373,  0.8555,  0.2227,\n",
       "          -0.4869, -0.8705,  0.8087,  0.3462, -0.6242,  1.0000, -0.4577, -0.9684,\n",
       "           0.9788,  0.9231,  0.5026, -0.5719,  0.8459, -1.0000,  0.5703, -0.1976,\n",
       "          -0.9850,  0.3782,  0.7032, -0.3358,  0.9639,  0.5812, -0.7467, -0.5447,\n",
       "          -0.3928, -0.9197, -0.4441, -0.3130,  0.1512, -0.2292, -0.5474, -0.4977,\n",
       "           0.4260, -0.6528, -0.3936,  0.8239,  0.3772,  0.6710,  0.4513, -0.5113,\n",
       "           0.4501, -0.9323,  0.6519, -0.4812, -0.9851, -0.5345, -0.9828,  0.7140,\n",
       "          -0.5041, -0.1840,  0.9429, -0.5921,  0.5717, -0.2566, -0.9764, -1.0000,\n",
       "          -0.6471, -0.7043, -0.6305, -0.3992, -0.9660, -0.9690,  0.6291,  0.9220,\n",
       "           0.4085,  0.9999, -0.3333,  0.9348, -0.4828, -0.8493,  0.7349, -0.5898,\n",
       "           0.8885,  0.0640, -0.5023,  0.2253, -0.6417,  0.3974, -0.8718, -0.1879,\n",
       "          -0.9085, -0.9193, -0.4798,  0.9383, -0.7846, -0.9833, -0.4707, -0.2482,\n",
       "          -0.4713,  0.7882,  0.8167,  0.4383, -0.5926,  0.5592,  0.5945,  0.6239,\n",
       "          -0.7796, -0.2305,  0.4708, -0.4465, -0.9728, -0.9723, -0.4082,  0.5381,\n",
       "           0.9837,  0.7525,  0.3887,  0.8205, -0.4370,  0.6969, -0.9575,  0.9744,\n",
       "          -0.2903,  0.4368, -0.8475,  0.7948, -0.7534,  0.4176,  0.7964, -0.7845,\n",
       "          -0.7384, -0.2401, -0.5895, -0.4913, -0.9414,  0.2828, -0.3462, -0.4358,\n",
       "          -0.1890,  0.9274,  0.9187,  0.5896,  0.6516,  0.5494, -0.8544, -0.4841,\n",
       "           0.1165,  0.2444,  0.2063,  0.9836, -0.8978, -0.0823, -0.9006, -0.9835,\n",
       "          -0.1076, -0.7951, -0.3047, -0.8010,  0.7978, -0.7618,  0.7202,  0.5316,\n",
       "          -0.9410, -0.6667,  0.4197, -0.6157,  0.5466, -0.3825,  0.9669,  0.9838,\n",
       "          -0.7029,  0.2116,  0.9560, -0.9916, -0.7705,  0.5799, -0.3896,  0.8323,\n",
       "          -0.7000,  0.9679,  0.9763,  0.8214, -0.8481, -0.9492, -0.6509, -0.8512,\n",
       "          -0.0303,  0.6465,  0.9662,  0.6154,  0.5413, -0.1099, -0.5983,  0.9851,\n",
       "          -0.9859, -0.9393, -0.8732, -0.2463, -0.9824,  0.9333,  0.4190,  0.8041,\n",
       "          -0.5307, -0.7788, -0.9458,  0.7107,  0.1765,  0.9725, -0.6081, -0.8217,\n",
       "          -0.6636, -0.9284, -0.0613, -0.2988, -0.7703,  0.0371, -0.9061,  0.5538,\n",
       "           0.5189,  0.6296, -0.9600,  0.9964,  1.0000,  0.9664,  0.8181,  0.7704,\n",
       "          -1.0000, -0.8168,  1.0000, -0.9972, -1.0000, -0.8357, -0.7343,  0.4328,\n",
       "          -1.0000, -0.2500,  0.0199, -0.8929,  0.8132,  0.9532,  0.9651, -1.0000,\n",
       "           0.6696,  0.8948, -0.5506,  0.9845, -0.6206,  0.9396,  0.7100,  0.5282,\n",
       "          -0.3711,  0.5552, -0.9908, -0.8151, -0.7887, -0.9280,  0.9999,  0.1897,\n",
       "          -0.7302, -0.8346,  0.5559, -0.1897, -0.0162, -0.9589, -0.5007,  0.5810,\n",
       "           0.8494,  0.3018,  0.4286, -0.5069,  0.3940,  0.5491,  0.0289,  0.6519,\n",
       "          -0.8986, -0.3785,  0.1384, -0.1238, -0.8582, -0.9719,  0.9400, -0.4294,\n",
       "           0.9190,  1.0000,  0.3961, -0.7918,  0.8001,  0.4439, -0.7219,  1.0000,\n",
       "           0.8998, -0.9663, -0.5732,  0.7878, -0.6960, -0.7486,  0.9990, -0.2853,\n",
       "          -0.8990, -0.5522,  0.9809, -0.9785,  0.9997, -0.8742, -0.9558,  0.9486,\n",
       "           0.9166, -0.6937, -0.6118,  0.1524, -0.8095,  0.3958, -0.8398,  0.6853,\n",
       "           0.4502, -0.1688,  0.8069, -0.5415, -0.6119,  0.3012, -0.6987, -0.3565,\n",
       "           0.9882,  0.5965, -0.2971,  0.1014, -0.3229, -0.8869, -0.9497,  0.6733,\n",
       "           1.0000, -0.4440,  0.9374, -0.5682, -0.1760,  0.1060,  0.6477,  0.6873,\n",
       "          -0.4636, -0.8392,  0.8632, -0.9429, -0.9859,  0.5670,  0.3324, -0.4197,\n",
       "           1.0000,  0.5807,  0.4218,  0.5785,  0.9953,  0.1389,  0.4943,  0.9657,\n",
       "           0.9703, -0.3316,  0.5808,  0.6067, -0.9538, -0.4469, -0.6760,  0.0596,\n",
       "          -0.9197, -0.0076, -0.9302,  0.9443,  0.9855,  0.4695,  0.3330,  0.8678,\n",
       "           1.0000, -0.9141,  0.5042,  0.5750,  0.4456, -1.0000, -0.7800, -0.4403,\n",
       "          -0.2629, -0.9560, -0.5647,  0.3993, -0.9404,  0.9355,  0.7858, -0.9721,\n",
       "          -0.9707, -0.6201,  0.7987,  0.0972, -0.9978, -0.7180, -0.5761,  0.6702,\n",
       "          -0.3372, -0.8715, -0.5001, -0.4806,  0.4864, -0.3105,  0.6153,  0.9664,\n",
       "           0.6159, -0.9237, -0.5371, -0.2590, -0.7943,  0.7715, -0.6380, -0.9780,\n",
       "          -0.3020,  1.0000, -0.5934,  0.9673,  0.7128,  0.4509, -0.3013,  0.3483,\n",
       "           0.9888,  0.4778, -0.9102, -0.9252,  0.6419, -0.4914,  0.7549,  0.8273,\n",
       "           0.9274,  0.7135,  0.9039,  0.2133, -0.1780,  0.1908,  0.9970, -0.0874,\n",
       "          -0.1620, -0.3594, -0.1343, -0.5565,  0.2690,  1.0000,  0.3159,  0.5515,\n",
       "          -0.9819, -0.9582, -0.8210,  1.0000,  0.8582, -0.4364,  0.6994,  0.6589,\n",
       "          -0.3305,  0.5900, -0.1860, -0.4303,  0.3998,  0.2495,  0.9315, -0.7043,\n",
       "          -0.9703, -0.6030,  0.4532, -0.9480,  1.0000, -0.6292, -0.4896, -0.5808,\n",
       "          -0.4069, -0.8050, -0.0868, -0.9746, -0.2471,  0.4031,  0.9271,  0.3323,\n",
       "          -0.5135, -0.7553,  0.9231,  0.8330, -0.9744, -0.9128,  0.9328, -0.9699,\n",
       "           0.6349,  1.0000,  0.5074,  0.4223,  0.3724, -0.5093,  0.5006, -0.3537,\n",
       "           0.6778, -0.9341, -0.5090, -0.4055,  0.3558, -0.2078, -0.6761,  0.5213,\n",
       "           0.3974, -0.5443, -0.7577, -0.1252,  0.4105,  0.7910, -0.3569, -0.1414,\n",
       "           0.1967, -0.2000, -0.8589, -0.3450, -0.5587, -1.0000,  0.6442, -1.0000,\n",
       "           0.7195,  0.6201, -0.2680,  0.7123,  0.8127,  0.8251, -0.5902, -0.9557,\n",
       "           0.0972,  0.7128, -0.3539, -0.4071, -0.5414,  0.4286, -0.2915,  0.2668,\n",
       "          -0.7580,  0.7897, -0.3600,  1.0000,  0.2838, -0.7503, -0.9357,  0.2878,\n",
       "          -0.3658,  1.0000, -0.6995, -0.9346,  0.5993, -0.8422, -0.8160,  0.5028,\n",
       "           0.1320, -0.8321, -0.9850,  0.9018,  0.5465, -0.6354,  0.5125, -0.4151,\n",
       "          -0.5562,  0.1340,  0.9697,  0.9835,  0.6795,  0.8099, -0.5769, -0.5767,\n",
       "           0.9617,  0.4025, -0.3543,  0.1535,  1.0000,  0.3983, -0.8893,  0.0394,\n",
       "          -0.9433, -0.3229, -0.8861,  0.3854,  0.3502,  0.8822, -0.2643,  0.9239,\n",
       "          -0.9048,  0.0413, -0.5129, -0.8062,  0.4157, -0.8901, -0.9759, -0.9730,\n",
       "           0.6868, -0.4419, -0.0726,  0.3497,  0.0185,  0.5740,  0.4760, -1.0000,\n",
       "           0.9043,  0.5067,  0.9769,  0.9438,  0.8501,  0.4952,  0.4028, -0.9678,\n",
       "          -0.9586, -0.4742, -0.2427,  0.6371,  0.6320,  0.8574,  0.4720, -0.5029,\n",
       "          -0.7394, -0.7983, -0.9376, -0.9889,  0.6237, -0.7265, -0.8327,  0.9503,\n",
       "           0.2320, -0.2578, -0.6173, -0.9363,  0.7396,  0.7179,  0.2970,  0.1473,\n",
       "           0.3638,  0.7433,  0.8866,  0.9547, -0.9666,  0.6108, -0.8644,  0.6083,\n",
       "           0.9148, -0.9443,  0.1940,  0.6181, -0.5196,  0.2853, -0.3979, -0.9259,\n",
       "           0.4504, -0.3925,  0.7328, -0.5107, -0.0474, -0.4839, -0.1444, -0.6302,\n",
       "          -0.8473,  0.6333,  0.4626,  0.8286,  0.9634, -0.1532, -0.5656, -0.1278,\n",
       "          -0.9355, -0.9004,  0.7907, -0.1022, -0.6615,  0.9000,  0.0160,  0.9433,\n",
       "           0.6461, -0.4118, -0.3314, -0.6814,  0.8078, -0.6281, -0.6302, -0.7394,\n",
       "           0.5898,  0.4710,  1.0000, -0.9218, -0.9644, -0.5291, -0.5097,  0.6100,\n",
       "          -0.5765, -1.0000,  0.4147, -0.7884,  0.9192, -0.7237,  0.9659, -0.6824,\n",
       "          -0.9387, -0.4639,  0.7601,  0.9015, -0.5920, -0.5166,  0.5143, -0.3056,\n",
       "           0.9910,  0.8088, -0.0802, -0.2125,  0.6256, -0.9530, -0.7157,  0.8775]],\n",
       "        device='cuda:0', grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put input on gpu and make prediction\n",
    "bert_output = bert(torch.tensor([input_ids]).cuda())\n",
    "bert_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Convert model to fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apex\n",
    "bert.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
